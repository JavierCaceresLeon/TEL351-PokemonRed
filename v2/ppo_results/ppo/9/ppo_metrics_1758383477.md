
---
# ğŸ¤– Informe Completo: PPO Agent (Deep Learning)
## PokÃ©mon Red - Agente PPO Preentrenado (Interrumpido por usuario)

### ğŸ¯ **Rendimiento Principal**
- **Recompensa Total:** `25.60`
- **Recompensa MÃ¡xima:** `25.60`
- **Recompensa MÃ­nima:** `0.00`
- **Recompensa Promedio/Paso:** `0.0877`
- **Pasos Totales:** `292`
- **Tipo de Agente:** PPO (Proximal Policy Optimization)

### â±ï¸ **AnÃ¡lisis Temporal**
- **Tiempo Total:** `20.96` segundos (0.35 minutos)
- **Pasos por Segundo:** `13.93`
- **Tiempo Promedio/Paso:** `71.78` ms

### ğŸ§  **InformaciÃ³n del Modelo**
- **Algoritmo:** PPO (Proximal Policy Optimization)
- **Modelo Cargado:** `runs\poke_26214400.zip`
- **Modo:** DeterminÃ­stico = False
- **Estado:** Modelo preentrenado cargado desde checkpoint

### ğŸ’» **Uso de Recursos del Sistema**
- **Memoria Actual:** `378.93` MB
- **Memoria Promedio:** `378.25` MB
- **CPU Actual:** `1196.8%`
- **Posiciones Ãšnicas Visitadas:** 1

### ğŸ“ˆ **EstadÃ­sticas de Acciones**
- **Total de Acciones:** 292
- **DistribuciÃ³n de Acciones:** {'A': 179, 'â†’': 36, 'â†‘': 26, 'â†': 22, 'â†“': 19, 'START': 6, 'B': 4}

### ğŸ“Š **AnÃ¡lisis de Recompensas**
- **Recompensa Media por AcciÃ³n:** 0.0877 (Ãºltimas 1000 acciones)
- **DesviaciÃ³n EstÃ¡ndar:** 0.6213
- **Recompensas Positivas:** 58 (19.9%)
- **Recompensas Negativas:** 0 (0.0%)

### ğŸ® **Comportamiento del Agente**
- **Modo de Control:** AutomÃ¡tico (IA controlando completamente)
- **Predicciones Realizadas:** 292
- **ExploraciÃ³n:** Controlada por polÃ­tica entrenada
- **Episodios Completados:** Variable (depende de duraciÃ³n)

### ğŸ”§ **ConfiguraciÃ³n del Entorno**
- **Juego:** Pokemon Red (Game Boy)
- **Frecuencia de AcciÃ³n:** 24 frames por acciÃ³n
- **Estado Inicial:** init.state
- **MÃ¡ximos Pasos:** 8,388,608
- **VisualizaciÃ³n:** Activada (ventana Game Boy)

### ğŸ“ **Notas Adicionales**
- Generado automÃ¡ticamente el 2025-09-20 12:51:17
- SesiÃ³n ID: 1758383477
- RazÃ³n de finalizaciÃ³n: Interrumpido por usuario
- Agente preentrenado usando reinforcement learning

### ğŸ†š **ComparaciÃ³n con Epsilon Greedy**
- **Ventaja PPO:** Aprendizaje por experiencia, comportamiento mÃ¡s sofisticado
- **Entrenamiento:** Miles de horas de experiencia vs. heurÃ­sticas manuales
- **Consistencia:** MÃ¡s predecible en situaciones conocidas
- **Adaptabilidad:** Mejor manejo de situaciones complejas

---
