{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81290335",
   "metadata": {},
   "source": [
    "# Entrenamiento Local de Agentes Pok√©mon\n",
    "Este cuaderno coordina el entrenamiento local de los agentes especializados y del agente h√≠brido usando las utilidades de `advanced_agents`. Cada secci√≥n describe qu√© configura o ejecuta para que puedas seguir el flujo sin consultar otros archivos. Para m√°s detalles sobre los scripts equivalentes por lotes revisa `README_LOCAL_TRAINING.md`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "635e6bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directorio de trabajo: c:\\Users\\javi1\\Documents\\repos_git\\TEL351-PokemonRed\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# FIX: Resolver conflicto de OpenMP (Error #15) que causa crash del kernel\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "import json\n",
    "import shutil\n",
    "import types\n",
    "import importlib\n",
    "from gymnasium import spaces\n",
    "\n",
    "# Configuraci√≥n de rutas locales\n",
    "project_path = os.getcwd()\n",
    "if project_path not in sys.path:\n",
    "    sys.path.append(project_path)\n",
    "\n",
    "baselines_path = os.path.join(project_path, 'baselines')\n",
    "if baselines_path not in sys.path:\n",
    "    sys.path.append(baselines_path)\n",
    "\n",
    "print(f\"Directorio de trabajo: {project_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee1438f",
   "metadata": {},
   "source": [
    "## 1. Configuraci√≥n de entorno\n",
    "Inicializa rutas y variables de entorno necesarias para que PyBoy y Stable-Baselines3 funcionen sin conflictos (por ejemplo, se habilita `KMP_DUPLICATE_LIB_OK` para evitar errores de OpenMP)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a71d552",
   "metadata": {},
   "source": [
    "## 1.1 Optimizaci√≥n con Numba (Opcional)\n",
    "Para acelerar los c√°lculos de recompensa (especialmente el c√°lculo de percentiles en el historial de p√©rdidas), se recomienda instalar `numba`. Si no est√° instalado, el c√≥digo usar√° una versi√≥n est√°ndar de Python m√°s lenta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aea20176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numba instalado: 0.62.1\n",
      "tqdm, rich e ipywidgets disponibles (barra de progreso activada)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import numba\n",
    "    print(f\"Numba instalado: {numba.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"Numba no detectado. Instalando...\")\n",
    "    !pip install numba\n",
    "    print(\"Instalaci√≥n completada. Por favor reinicia el kernel si es necesario.\")\n",
    "\n",
    "# Verificar e instalar dependencias para la barra de progreso\n",
    "try:\n",
    "    import tqdm\n",
    "    import rich\n",
    "    import ipywidgets\n",
    "    print(f\"tqdm, rich e ipywidgets disponibles (barra de progreso activada)\")\n",
    "except ImportError:\n",
    "    print(\"Instalando dependencias para habilitar la barra de progreso...\")\n",
    "    !pip install tqdm rich ipywidgets\n",
    "    print(\"Instalaci√≥n completada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "068ca310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Verificando instalaci√≥n de PyTorch...\n",
      "\n",
      "============================================================\n",
      "‚ùå ERROR CR√çTICO AL CARGAR PYTORCH\n",
      "============================================================\n",
      "\n",
      "üî¥ ERROR WinError 126: Archivos DLL faltantes o corruptos\n",
      "\n",
      "Este error indica que PyTorch est√° instalado pero corrupto.\n",
      "\n",
      "üìã SOLUCI√ìN AUTOM√ÅTICA:\n",
      "   1. Ejecuta la SIGUIENTE celda (reparaci√≥n de PyTorch)\n",
      "   2. Reinicia el kernel (Bot√≥n Restart ‚Üª arriba)\n",
      "   3. Vuelve a ejecutar esta celda\n",
      "\n",
      "‚ö†Ô∏è NO PUEDES ENTRENAR CON ESTE ERROR\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import warnings\n",
    "\n",
    "print(\"üîß Verificando instalaci√≥n de PyTorch...\")\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"‚úÖ PyTorch versi√≥n: {torch.__version__}\")\n",
    "    print(f\"‚úÖ CUDA versi√≥n: {torch.version.cuda}\")\n",
    "    \n",
    "    # Verificar GPU\n",
    "    gpu_available = torch.cuda.is_available()\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    if gpu_available:\n",
    "        print(f\"üéÆ GPU DETECTADA\")\n",
    "        print(f\"   Nombre: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"   CUDA Capability: {torch.cuda.get_device_capability(0)}\")\n",
    "        print(f\"   Memoria Total: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è GPU NO DETECTADA - Usando CPU\")\n",
    "        print(\"\\nCausas posibles:\")\n",
    "        print(\"   1. Drivers NVIDIA desactualizados\")\n",
    "        print(\"   2. PyTorch CPU-only instalado (sin soporte CUDA)\")\n",
    "        print(\"   3. CUDA no compatible con tu GPU\")\n",
    "        print(\"\\nPara RTX 3050, necesitas:\")\n",
    "        print(\"   - CUDA 11.8 o 12.x\")\n",
    "        print(\"   - PyTorch compilado con soporte CUDA\")\n",
    "        print(\"\\nEjecuta la siguiente celda para reinstalar PyTorch con GPU.\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "except OSError as e:\n",
    "    error_msg = str(e)\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"‚ùå ERROR CR√çTICO AL CARGAR PYTORCH\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if \"126\" in error_msg or \"caffe2_nvrtc.dll\" in error_msg:\n",
    "        print(\"\\nüî¥ ERROR WinError 126: Archivos DLL faltantes o corruptos\")\n",
    "        print(\"\\nEste error indica que PyTorch est√° instalado pero corrupto.\")\n",
    "        print(\"\\nüìã SOLUCI√ìN AUTOM√ÅTICA:\")\n",
    "        print(\"   1. Ejecuta la SIGUIENTE celda (reparaci√≥n de PyTorch)\")\n",
    "        print(\"   2. Reinicia el kernel (Bot√≥n Restart ‚Üª arriba)\")\n",
    "        print(\"   3. Vuelve a ejecutar esta celda\")\n",
    "        \n",
    "    elif \"127\" in error_msg:\n",
    "        print(\"\\nüî¥ ERROR WinError 127: M√≥dulo no encontrado\")\n",
    "        print(\"\\nFalta una dependencia de PyTorch.\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"\\nError desconocido: {error_msg}\")\n",
    "    \n",
    "    print(\"\\n‚ö†Ô∏è NO PUEDES ENTRENAR CON ESTE ERROR\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"‚ùå PYTORCH NO INSTALADO\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nError: {e}\")\n",
    "    print(\"\\nüìã INSTALACI√ìN R√ÅPIDA:\")\n",
    "    print(\"   Ejecuta en una celda:\")\n",
    "    print(\"   !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error inesperado: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5163a7c5",
   "metadata": {},
   "source": [
    "## 1.2 Soluci√≥n de Problemas de GPU\n",
    "Si la celda anterior indica que **PyTorch est√° usando CPU**, es probable que tengas instalada una versi√≥n incorrecta de PyTorch o que falten los drivers de CUDA.\n",
    "Para arreglarlo en tu **RTX 3050**, ejecuta la siguiente celda para reinstalar una versi√≥n estable de PyTorch con soporte CUDA 12.4 (compatible con tus drivers actuales).\n",
    "**Nota:** Despu√©s de la instalaci√≥n, deber√°s reiniciar el kernel del notebook (Bot√≥n \"Restart\" en la barra superior)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09339d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß REPARACI√ìN DE PYTORCH PARA RTX 3050\n",
      "======================================================================\n",
      "\n",
      "‚ö†Ô∏è ADVERTENCIA:\n",
      "   Esta celda desinstalar√° y reinstalar√° PyTorch.\n",
      "   Si ya tienes PyTorch funcionando, NO ejecutes esto.\n",
      "\n",
      "¬øContinuar? (Ejecuta la celda para confirmar)\n",
      "\n",
      "Entorno detectado: envs\n",
      "\n",
      "üìã Comandos a ejecutar:\n",
      "   1. pip uninstall -y torch torchvision torchaudio\n",
      "   2. pip cache purge\n",
      "   3. pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
      "\n",
      "======================================================================\n",
      "EJECUTANDO REPARACI√ìN...\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[1/3] pip uninstall -y torch torchvision torchaudio\n",
      "----------------------------------------------------------------------\n",
      "‚úÖ Paso 1 completado\n",
      "\n",
      "[2/3] pip cache purge\n",
      "----------------------------------------------------------------------\n",
      "‚úÖ Paso 1 completado\n",
      "\n",
      "[2/3] pip cache purge\n",
      "----------------------------------------------------------------------\n",
      "Files removed: 0 (0 bytes)\n",
      "\n",
      "‚úÖ Paso 2 completado\n",
      "\n",
      "[3/3] pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
      "----------------------------------------------------------------------\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torch-2.5.1%2Bcu121-cp310-cp310-win_amd64.whl (2449.4 MB)\n",
      "     ---------------------------------------- 0.0/2.4 GB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/2.4 GB 67.1 MB/s eta 0:00:37\n",
      "     ---------------------------------------- 0.0/2.4 GB 74.4 MB/s eta 0:00:33\n",
      "      --------------------------------------- 0.0/2.4 GB 71.5 MB/s eta 0:00:34\n",
      "      --------------------------------------- 0.1/2.4 GB 68.7 MB/s eta 0:00:35\n",
      "     - -------------------------------------- 0.1/2.4 GB 68.6 MB/s eta 0:00:35\n",
      "     - -------------------------------------- 0.1/2.4 GB 71.0 MB/s eta 0:00:34\n",
      "     - -------------------------------------- 0.1/2.4 GB 71.3 MB/s eta 0:00:33\n",
      "     - -------------------------------------- 0.1/2.4 GB 72.3 MB/s eta 0:00:33\n",
      "     -- ------------------------------------- 0.1/2.4 GB 72.2 MB/s eta 0:00:33\n",
      "     -- ------------------------------------- 0.1/2.4 GB 71.8 MB/s eta 0:00:33\n",
      "     -- ------------------------------------- 0.2/2.4 GB 71.9 MB/s eta 0:00:32\n",
      "     -- ------------------------------------- 0.2/2.4 GB 71.3 MB/s eta 0:00:32\n",
      "     --- ------------------------------------ 0.2/2.4 GB 70.6 MB/s eta 0:00:33\n",
      "     --- ------------------------------------ 0.2/2.4 GB 70.0 MB/s eta 0:00:33\n",
      "     --- ------------------------------------ 0.2/2.4 GB 69.4 MB/s eta 0:00:33\n",
      "     --- ------------------------------------ 0.2/2.4 GB 69.9 MB/s eta 0:00:32\n",
      "     --- ------------------------------------ 0.2/2.4 GB 69.4 MB/s eta 0:00:32\n",
      "     ---- ----------------------------------- 0.3/2.4 GB 70.3 MB/s eta 0:00:32\n",
      "     ---- ----------------------------------- 0.3/2.4 GB 71.3 MB/s eta 0:00:31\n",
      "     ---- ----------------------------------- 0.3/2.4 GB 71.3 MB/s eta 0:00:31\n",
      "     ----- ---------------------------------- 0.3/2.4 GB 72.6 MB/s eta 0:00:30\n",
      "     ----- ---------------------------------- 0.3/2.4 GB 73.2 MB/s eta 0:00:30\n",
      "     ----- ---------------------------------- 0.3/2.4 GB 72.9 MB/s eta 0:00:29\n",
      "     ----- ---------------------------------- 0.4/2.4 GB 73.2 MB/s eta 0:00:29\n",
      "     ------ --------------------------------- 0.4/2.4 GB 73.2 MB/s eta 0:00:29\n",
      "     ------ --------------------------------- 0.4/2.4 GB 73.5 MB/s eta 0:00:28\n",
      "     ------ --------------------------------- 0.4/2.4 GB 74.2 MB/s eta 0:00:28\n",
      "     ------- -------------------------------- 0.4/2.4 GB 76.5 MB/s eta 0:00:27\n",
      "     ------- -------------------------------- 0.4/2.4 GB 76.5 MB/s eta 0:00:27\n",
      "     ------- -------------------------------- 0.5/2.4 GB 77.2 MB/s eta 0:00:26\n",
      "     ------- -------------------------------- 0.5/2.4 GB 79.0 MB/s eta 0:00:25\n",
      "     -------- ------------------------------- 0.5/2.4 GB 79.8 MB/s eta 0:00:25\n",
      "     -------- ------------------------------- 0.5/2.4 GB 80.2 MB/s eta 0:00:25\n",
      "     -------- ------------------------------- 0.5/2.4 GB 81.0 MB/s eta 0:00:24\n",
      "     -------- ------------------------------- 0.5/2.4 GB 80.2 MB/s eta 0:00:24\n",
      "     --------- ------------------------------ 0.6/2.4 GB 80.2 MB/s eta 0:00:24\n",
      "     --------- ------------------------------ 0.6/2.4 GB 79.4 MB/s eta 0:00:24\n",
      "     --------- ------------------------------ 0.6/2.4 GB 78.3 MB/s eta 0:00:24\n",
      "     --------- ------------------------------ 0.6/2.4 GB 77.6 MB/s eta 0:00:24\n",
      "     ---------- ----------------------------- 0.6/2.4 GB 76.9 MB/s eta 0:00:24\n",
      "     ---------- ----------------------------- 0.6/2.4 GB 75.1 MB/s eta 0:00:25\n",
      "     ---------- ----------------------------- 0.6/2.4 GB 74.1 MB/s eta 0:00:25\n",
      "     ---------- ----------------------------- 0.7/2.4 GB 72.9 MB/s eta 0:00:25\n",
      "     ---------- ----------------------------- 0.7/2.4 GB 71.6 MB/s eta 0:00:25\n",
      "     ----------- ---------------------------- 0.7/2.4 GB 70.7 MB/s eta 0:00:26\n",
      "     ----------- ---------------------------- 0.7/2.4 GB 69.2 MB/s eta 0:00:26\n",
      "     ----------- ---------------------------- 0.7/2.4 GB 69.5 MB/s eta 0:00:26\n",
      "     ----------- ---------------------------- 0.7/2.4 GB 69.5 MB/s eta 0:00:25\n",
      "     ----------- ---------------------------- 0.7/2.4 GB 69.5 MB/s eta 0:00:25\n",
      "     ------------ --------------------------- 0.7/2.4 GB 65.0 MB/s eta 0:00:27\n",
      "     ------------ --------------------------- 0.7/2.4 GB 64.5 MB/s eta 0:00:27\n",
      "     ------------ --------------------------- 0.8/2.4 GB 64.5 MB/s eta 0:00:27\n",
      "     ------------ --------------------------- 0.8/2.4 GB 64.2 MB/s eta 0:00:26\n",
      "     ------------- -------------------------- 0.8/2.4 GB 64.5 MB/s eta 0:00:26\n",
      "     ------------- -------------------------- 0.8/2.4 GB 64.5 MB/s eta 0:00:26\n",
      "     ------------- -------------------------- 0.8/2.4 GB 65.0 MB/s eta 0:00:25\n",
      "     ------------- -------------------------- 0.8/2.4 GB 65.2 MB/s eta 0:00:25\n",
      "     -------------- ------------------------- 0.9/2.4 GB 65.7 MB/s eta 0:00:25\n",
      "     -------------- ------------------------- 0.9/2.4 GB 66.8 MB/s eta 0:00:24\n",
      "     -------------- ------------------------- 0.9/2.4 GB 68.1 MB/s eta 0:00:23\n",
      "     -------------- ------------------------- 0.9/2.4 GB 69.5 MB/s eta 0:00:23\n",
      "     --------------- ------------------------ 0.9/2.4 GB 70.4 MB/s eta 0:00:22\n",
      "     --------------- ------------------------ 0.9/2.4 GB 71.6 MB/s eta 0:00:21\n",
      "     --------------- ------------------------ 1.0/2.4 GB 71.9 MB/s eta 0:00:21\n",
      "     ---------------- ----------------------- 1.0/2.4 GB 72.9 MB/s eta 0:00:21\n",
      "     ---------------- ----------------------- 1.0/2.4 GB 79.8 MB/s eta 0:00:19\n",
      "     ---------------- ----------------------- 1.0/2.4 GB 81.0 MB/s eta 0:00:18\n",
      "     ----------------- ---------------------- 1.0/2.4 GB 81.8 MB/s eta 0:00:18\n",
      "     ----------------- ---------------------- 1.1/2.4 GB 82.1 MB/s eta 0:00:17\n",
      "     ----------------- ---------------------- 1.1/2.4 GB 81.8 MB/s eta 0:00:17\n",
      "     ----------------- ---------------------- 1.1/2.4 GB 80.6 MB/s eta 0:00:17\n",
      "     ------------------ --------------------- 1.1/2.4 GB 81.0 MB/s eta 0:00:17\n",
      "     ------------------ --------------------- 1.1/2.4 GB 80.6 MB/s eta 0:00:17\n",
      "     ------------------ --------------------- 1.1/2.4 GB 80.6 MB/s eta 0:00:17\n",
      "     ------------------ --------------------- 1.2/2.4 GB 80.6 MB/s eta 0:00:17\n",
      "     ------------------- -------------------- 1.2/2.4 GB 79.4 MB/s eta 0:00:17\n",
      "     ------------------- -------------------- 1.2/2.4 GB 79.0 MB/s eta 0:00:17\n",
      "     ------------------- -------------------- 1.2/2.4 GB 78.3 MB/s eta 0:00:17\n",
      "     ------------------- -------------------- 1.2/2.4 GB 78.3 MB/s eta 0:00:16\n",
      "     ------------------- -------------------- 1.2/2.4 GB 77.2 MB/s eta 0:00:16\n",
      "     -------------------- ------------------- 1.2/2.4 GB 76.9 MB/s eta 0:00:16\n",
      "\n",
      "‚ö†Ô∏è Advertencias/Errores:\n",
      "ERROR: Could not install packages due to an OSError: [Errno 28] No space left on device\n",
      "\n",
      "\n",
      "‚ö†Ô∏è Paso 3 complet√≥ con warnings (normal durante desinstalaci√≥n)\n",
      "\n",
      "======================================================================\n",
      "‚úÖ REPARACI√ìN COMPLETADA\n",
      "======================================================================\n",
      "\n",
      "üîÑ SIGUIENTE PASO OBLIGATORIO:\n",
      "   1. Haz clic en 'Restart' (bot√≥n ‚Üª arriba)\n",
      "   2. Ejecuta de nuevo la celda de verificaci√≥n de PyTorch\n",
      "   3. Deber√≠as ver 'GPU DETECTADA'\n",
      "\n",
      "Si sigue fallando, ejecuta desde terminal:\n",
      "   conda activate envs\n",
      "   python -c \"import torch; print(torch.cuda.is_available())\"\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==================== REPARACI√ìN DE PYTORCH (RTX 3050) ====================\n",
    "# Ejecuta esta celda SOLO si la anterior mostr√≥ WinError 126 o GPU no detectada\n",
    "# IMPORTANTE: Despu√©s de ejecutar, DEBES REINICIAR EL KERNEL\n",
    "# ===========================================================================\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "print(\"üîß REPARACI√ìN DE PYTORCH PARA RTX 3050\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\n‚ö†Ô∏è ADVERTENCIA:\")\n",
    "print(\"   Esta celda desinstalar√° y reinstalar√° PyTorch.\")\n",
    "print(\"   Si ya tienes PyTorch funcionando, NO ejecutes esto.\")\n",
    "print(\"\\n¬øContinuar? (Ejecuta la celda para confirmar)\")\n",
    "\n",
    "# Detectar el entorno de conda\n",
    "env_name = sys.executable.split(\"\\\\\")[-3] if \"envs\" in sys.executable else \"base\"\n",
    "print(f\"\\nEntorno detectado: {env_name}\")\n",
    "\n",
    "# Comandos de reparaci√≥n\n",
    "commands = [\n",
    "    # 1. Desinstalar PyTorch corrupto\n",
    "    \"pip uninstall -y torch torchvision torchaudio\",\n",
    "    \n",
    "    # 2. Limpiar cach√© de pip\n",
    "    \"pip cache purge\",\n",
    "    \n",
    "    # 3. Reinstalar PyTorch con CUDA 12.1 (compatible con RTX 3050)\n",
    "    \"pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\"\n",
    "]\n",
    "\n",
    "print(\"\\nüìã Comandos a ejecutar:\")\n",
    "for i, cmd in enumerate(commands, 1):\n",
    "    print(f\"   {i}. {cmd}\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"EJECUTANDO REPARACI√ìN...\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "try:\n",
    "    for i, cmd in enumerate(commands, 1):\n",
    "        print(f\"\\n[{i}/{len(commands)}] {cmd}\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        result = subprocess.run(\n",
    "            cmd,\n",
    "            shell=True,\n",
    "            capture_output=True,\n",
    "            text=True\n",
    "        )\n",
    "        \n",
    "        # Mostrar output\n",
    "        if result.stdout:\n",
    "            print(result.stdout)\n",
    "        if result.returncode != 0 and result.stderr:\n",
    "            print(f\"‚ö†Ô∏è Advertencias/Errores:\\n{result.stderr}\")\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(f\"‚úÖ Paso {i} completado\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Paso {i} complet√≥ con warnings (normal durante desinstalaci√≥n)\")\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"‚úÖ REPARACI√ìN COMPLETADA\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nüîÑ SIGUIENTE PASO OBLIGATORIO:\")\n",
    "    print(\"   1. Haz clic en 'Restart' (bot√≥n ‚Üª arriba)\")\n",
    "    print(\"   2. Ejecuta de nuevo la celda de verificaci√≥n de PyTorch\")\n",
    "    print(\"   3. Deber√≠as ver 'GPU DETECTADA'\")\n",
    "    print(\"\\nSi sigue fallando, ejecuta desde terminal:\")\n",
    "    print(f\"   conda activate {env_name}\")\n",
    "    print(\"   python -c \\\"import torch; print(torch.cuda.is_available())\\\"\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå ERROR DURANTE LA REPARACI√ìN: {e}\")\n",
    "    print(\"\\nSOLUCI√ìN MANUAL:\")\n",
    "    print(\"   1. Abre una terminal (Ctrl+√ë)\")\n",
    "    print(f\"   2. conda activate {env_name}\")\n",
    "    print(\"   3. Copia y pega estos comandos UNO POR UNO:\")\n",
    "    for cmd in commands:\n",
    "        print(f\"      {cmd}\")\n",
    "    print(\"\\n   4. Reinicia el kernel del notebook\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4ef69b",
   "metadata": {},
   "source": [
    "### üîß Reparaci√≥n R√°pida: M√≥dulo _dynamo Corrupto\n",
    "\n",
    "**Si ves el error**: `No module named 'torch._C._dynamo.guards'`\n",
    "\n",
    "Este error espec√≠fico indica que PyTorch se instal√≥ correctamente pero algunos m√≥dulos internos est√°n corruptos o incompletos. La causa com√∫n es:\n",
    "- Instalaci√≥n interrumpida\n",
    "- Versi√≥n incompatible de dependencies\n",
    "- Cach√© de pip corrupto\n",
    "\n",
    "**Soluci√≥n r√°pida** (ejecuta en TERMINAL, no en notebook):\n",
    "```powershell\n",
    "conda activate pokeenv\n",
    "pip uninstall -y torch torchvision torchaudio\n",
    "pip cache purge\n",
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121 --no-cache-dir\n",
    "```\n",
    "\n",
    "Despu√©s de ejecutar los comandos, **reinicia el kernel** y vuelve a probar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec427596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß REPARACI√ìN DE M√ìDULO _DYNAMO CORRUPTO\n",
      "======================================================================\n",
      "\n",
      "üìç Reparando PyTorch en: pokeenv\n",
      "üêç Python: c:\\Users\\javi1\\anaconda3\\envs\\pokeenv\\python.exe\n",
      "\n",
      "‚è±Ô∏è Tiempo estimado: 3-5 minutos\n",
      "\n",
      "üìã Ejecutando reparaci√≥n...\n",
      "\n",
      "[1/3] Ejecutando...\n",
      "----------------------------------------------------------------------\n",
      "‚úÖ Paso 1 completado\n",
      "\n",
      "[2/3] Ejecutando...\n",
      "----------------------------------------------------------------------\n",
      "‚úÖ Paso 1 completado\n",
      "\n",
      "[2/3] Ejecutando...\n",
      "----------------------------------------------------------------------\n",
      "‚úÖ Paso 2 completado\n",
      "\n",
      "[3/3] Ejecutando...\n",
      "----------------------------------------------------------------------\n",
      "‚úÖ Paso 2 completado\n",
      "\n",
      "[3/3] Ejecutando...\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ========== REPARACI√ìN AUTOM√ÅTICA DE TORCH._DYNAMO ==========\n",
    "# Ejecuta esta celda si viste el error de _dynamo.guards\n",
    "# Repara PyTorch en EL MISMO ENTORNO donde corre el kernel\n",
    "# IMPORTANTE: Despu√©s de ejecutar, DEBES REINICIAR EL KERNEL\n",
    "# =============================================================\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"üîß REPARACI√ìN DE M√ìDULO _DYNAMO CORRUPTO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Usar el pip del mismo Python que el kernel\n",
    "python_exe = sys.executable\n",
    "pip_cmd = f'\"{python_exe}\" -m pip'\n",
    "\n",
    "# Detectar entorno\n",
    "env_name = \"unknown\"\n",
    "if \"envs\" in python_exe:\n",
    "    parts = python_exe.split(os.sep)\n",
    "    try:\n",
    "        env_idx = parts.index(\"envs\")\n",
    "        env_name = parts[env_idx + 1]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(f\"\\nüìç Reparando PyTorch en: {env_name}\")\n",
    "print(f\"üêç Python: {python_exe}\")\n",
    "print(f\"\\n‚è±Ô∏è Tiempo estimado: 3-5 minutos\\n\")\n",
    "\n",
    "# Comandos usando el pip correcto\n",
    "commands = [\n",
    "    f\"{pip_cmd} uninstall -y torch torchvision torchaudio\",\n",
    "    f\"{pip_cmd} cache purge\",\n",
    "    f\"{pip_cmd} install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121 --no-cache-dir --force-reinstall\"\n",
    "]\n",
    "\n",
    "print(\"üìã Ejecutando reparaci√≥n...\\n\")\n",
    "\n",
    "for i, cmd in enumerate(commands, 1):\n",
    "    print(f\"[{i}/{len(commands)}] Ejecutando...\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            cmd,\n",
    "            shell=True,\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=300\n",
    "        )\n",
    "        \n",
    "        # Mostrar solo l√≠neas relevantes\n",
    "        if result.stdout:\n",
    "            lines = result.stdout.split('\\n')\n",
    "            important_lines = [\n",
    "                line for line in lines \n",
    "                if any(word in line.lower() for word in [\n",
    "                    'success', 'installing', 'uninstalling', \n",
    "                    'error', 'warning', 'downloading', 'collecting'\n",
    "                ])\n",
    "            ]\n",
    "            for line in important_lines[:10]:  # M√°ximo 10 l√≠neas\n",
    "                print(line)\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(f\"‚úÖ Paso {i} completado\\n\")\n",
    "        else:\n",
    "            if i == 1:  # Desinstalaci√≥n puede fallar si no est√° instalado\n",
    "                print(f\"‚ö†Ô∏è Paso {i} con warnings (puede ser normal si no estaba instalado)\\n\")\n",
    "            else:\n",
    "                print(f\"‚ùå Paso {i} fall√≥. Revisa errores arriba.\\n\")\n",
    "                if result.stderr:\n",
    "                    print(\"Stderr:\", result.stderr[:500])\n",
    "            \n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(f\"‚ùå Timeout en paso {i} (>5 min).\\n\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error en paso {i}: {e}\\n\")\n",
    "        break\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"‚úÖ PROCESO COMPLETADO\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nüîÑ PASOS SIGUIENTES OBLIGATORIOS:\")\n",
    "print(\"   1. Haz clic en 'Restart' (bot√≥n ‚Üª en la barra superior)\")\n",
    "print(\"   2. Ejecuta la celda anterior 'IDENTIFICAR ENTORNO'\")\n",
    "print(\"   3. Deber√≠a mostrar: ‚úÖ M√≥dulo _dynamo.guards: OK\")\n",
    "print(\"   4. Ejecuta la celda de diagn√≥stico pre-entrenamiento\")\n",
    "print(\"   5. Si todo OK, ejecuta el entrenamiento\")\n",
    "print(\"\\nüìä Para verificar manualmente:\")\n",
    "print(\"   python -c \\\"from torch._C._dynamo.guards import GlobalStateGuard; print('OK')\\\"\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2673022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç DIAGN√ìSTICO DEL ENTORNO DEL KERNEL\n",
      "======================================================================\n",
      "üìç Entorno detectado: pokeenv\n",
      "üìÇ Python ejecutable: c:\\Users\\javi1\\anaconda3\\envs\\pokeenv\\python.exe\n",
      "üêç Versi√≥n: 3.10.19\n",
      "\n",
      "======================================================================\n",
      "VERIFICANDO PYTORCH EN ESTE ENTORNO...\n",
      "======================================================================\n",
      "‚úÖ PyTorch instalado: 2.5.1+cu121\n",
      "   Ubicaci√≥n: c:\\Users\\javi1\\anaconda3\\envs\\pokeenv\\lib\\site-packages\\torch\n",
      "   CUDA disponible: True\n",
      "‚úÖ M√≥dulo _dynamo.guards: OK\n",
      "\n",
      "======================================================================\n",
      "RECOMENDACI√ìN:\n",
      "======================================================================\n",
      "‚úÖ PyTorch funciona correctamente. No necesitas reparaci√≥n.\n",
      "\n",
      "Si a√∫n ves errores, el problema puede estar en:\n",
      "   - M√≥dulos de advanced_agents\n",
      "   - Configuraci√≥n del entorno\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ========== IDENTIFICAR Y REPARAR EL ENTORNO REAL DEL KERNEL ==========\n",
    "# Esta celda detecta qu√© Python/entorno est√° usando el kernel\n",
    "# y repara PyTorch en el lugar correcto\n",
    "# =======================================================================\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "print(\"üîç DIAGN√ìSTICO DEL ENTORNO DEL KERNEL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Identificar el Python actual\n",
    "python_exe = sys.executable\n",
    "python_version = sys.version\n",
    "env_name = \"unknown\"\n",
    "\n",
    "# Detectar si es conda\n",
    "if \"envs\" in python_exe:\n",
    "    parts = python_exe.split(os.sep)\n",
    "    try:\n",
    "        env_idx = parts.index(\"envs\")\n",
    "        env_name = parts[env_idx + 1]\n",
    "    except (ValueError, IndexError):\n",
    "        env_name = \"conda_base\"\n",
    "elif \"anaconda3\" in python_exe.lower() and \"envs\" not in python_exe:\n",
    "    env_name = \"base\"\n",
    "\n",
    "print(f\"üìç Entorno detectado: {env_name}\")\n",
    "print(f\"üìÇ Python ejecutable: {python_exe}\")\n",
    "print(f\"üêç Versi√≥n: {python_version.split()[0]}\")\n",
    "\n",
    "# Verificar estado de PyTorch\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"VERIFICANDO PYTORCH EN ESTE ENTORNO...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    torch_version = torch.__version__\n",
    "    torch_path = torch.__file__\n",
    "    cuda_available = torch.cuda.is_available()\n",
    "    \n",
    "    print(f\"‚úÖ PyTorch instalado: {torch_version}\")\n",
    "    print(f\"   Ubicaci√≥n: {os.path.dirname(torch_path)}\")\n",
    "    print(f\"   CUDA disponible: {cuda_available}\")\n",
    "    \n",
    "    # Intentar importar el m√≥dulo problem√°tico\n",
    "    try:\n",
    "        from torch._C._dynamo.guards import GlobalStateGuard\n",
    "        print(f\"‚úÖ M√≥dulo _dynamo.guards: OK\")\n",
    "        dynamo_ok = True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå M√≥dulo _dynamo.guards: CORRUPTO\")\n",
    "        print(f\"   Error: {e}\")\n",
    "        dynamo_ok = False\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"‚ùå PyTorch NO instalado en este entorno\")\n",
    "    torch_version = None\n",
    "    dynamo_ok = False\n",
    "\n",
    "# Decidir acci√≥n\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"RECOMENDACI√ìN:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if torch_version and dynamo_ok:\n",
    "    print(\"‚úÖ PyTorch funciona correctamente. No necesitas reparaci√≥n.\")\n",
    "    print(\"\\nSi a√∫n ves errores, el problema puede estar en:\")\n",
    "    print(\"   - M√≥dulos de advanced_agents\")\n",
    "    print(\"   - Configuraci√≥n del entorno\")\n",
    "    \n",
    "elif torch_version and not dynamo_ok:\n",
    "    print(\"‚ö†Ô∏è PyTorch est√° instalado pero el m√≥dulo _dynamo est√° CORRUPTO\")\n",
    "    print(\"\\nüîß EJECUTA LA SIGUIENTE CELDA para reparar autom√°ticamente\")\n",
    "    print(\"   (Desinstalar√° y reinstalar√° PyTorch en el entorno correcto)\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå PyTorch NO est√° instalado en este entorno\")\n",
    "    print(f\"\\nüìã Para instalar PyTorch en '{env_name}':\")\n",
    "    print(f\"   1. Abre terminal\")\n",
    "    print(f\"   2. conda activate {env_name}\")\n",
    "    print(f\"   3. pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\")\n",
    "    print(f\"   4. Reinicia el kernel del notebook\")\n",
    "\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cf52d6",
   "metadata": {},
   "source": [
    "### ‚ö° Soluci√≥n R√°pida: Deshabilitar _dynamo (Workaround)\n",
    "\n",
    "Si la reparaci√≥n de PyTorch tarda mucho o sigue fallando, puedes **deshabilitar temporalmente** el m√≥dulo `_dynamo` que causa el error. Esto permite entrenar mientras reparas PyTorch en segundo plano.\n",
    "\n",
    "**Ejecuta la siguiente celda** para aplicar el workaround."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa064134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö° APLICANDO WORKAROUND PARA _DYNAMO\n",
      "============================================================\n",
      "‚úÖ Variable TORCH_COMPILE_DISABLE = 1\n",
      "‚úÖ Variable TORCHDYNAMO_DISABLE = 1\n",
      "‚úÖ Graph executor optimizations deshabilitadas\n",
      "\n",
      "============================================================\n",
      "WORKAROUND APLICADO\n",
      "============================================================\n",
      "\n",
      "üìã Qu√© hace esto:\n",
      "   - Deshabilita torch.compile y _dynamo\n",
      "   - Permite entrenar sin el m√≥dulo corrupto\n",
      "   - Rendimiento puede ser ~5-10% m√°s lento\n",
      "\n",
      "‚úÖ Ahora puedes ejecutar el entrenamiento normalmente\n",
      "\n",
      "‚ö†Ô∏è Para reparaci√≥n permanente:\n",
      "   1. Ejecuta la celda de reparaci√≥n de PyTorch\n",
      "   2. Reinicia el kernel\n",
      "   3. NO ejecutes este workaround de nuevo\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ========== WORKAROUND AGRESIVO: BLOQUEAR IMPORTS CORRUPTOS ==========\n",
    "# PyTorch est√° MUY corrupto. Este workaround bloquea los imports problem√°ticos\n",
    "# EJECUTA ESTA CELDA ANTES DE CUALQUIER OTRA QUE USE TORCH\n",
    "# =====================================================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "print(\"‚ö° APLICANDO WORKAROUND AGRESIVO PARA PYTORCH CORRUPTO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Paso 1: Deshabilitar torch.compile y dynamo\n",
    "os.environ['TORCH_COMPILE_DISABLE'] = '1'\n",
    "os.environ['TORCHDYNAMO_DISABLE'] = '1'\n",
    "os.environ['TORCH_USE_RTLD_GLOBAL'] = 'YES'\n",
    "print(\"‚úÖ Variables de entorno configuradas\")\n",
    "\n",
    "# Paso 2: Monkey-patch torch._compile para evitar imports\n",
    "import importlib.util\n",
    "\n",
    "def disable_compile_module():\n",
    "    \"\"\"Reemplaza torch._compile con un m√≥dulo dummy que no importa _dynamo\"\"\"\n",
    "    if 'torch._compile' in sys.modules:\n",
    "        del sys.modules['torch._compile']\n",
    "    \n",
    "    # Crear m√≥dulo dummy\n",
    "    import types\n",
    "    dummy_compile = types.ModuleType('torch._compile')\n",
    "    \n",
    "    # Funci√≥n dummy que no hace nada\n",
    "    def dummy_inner(func=None, *args, **kwargs):\n",
    "        if func is None:\n",
    "            return lambda f: f\n",
    "        return func\n",
    "    \n",
    "    dummy_compile.inner = dummy_inner\n",
    "    sys.modules['torch._compile'] = dummy_compile\n",
    "    print(\"‚úÖ torch._compile parcheado\")\n",
    "\n",
    "# Paso 3: Importar torch CON el parche activo\n",
    "try:\n",
    "    disable_compile_module()\n",
    "    import torch\n",
    "    \n",
    "    # Verificar que torch funciona\n",
    "    print(f\"‚úÖ PyTorch {torch.__version__} cargado\")\n",
    "    print(f\"‚úÖ CUDA disponible: {torch.cuda.is_available()}\")\n",
    "    \n",
    "    # Parchear torch.optim para evitar llamadas a _compile\n",
    "    original_adam_init = torch.optim.Adam.__init__\n",
    "    \n",
    "    def patched_adam_init(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8,\n",
    "                         weight_decay=0, amsgrad=False, foreach=None,\n",
    "                         maximize=False, capturable=False, differentiable=False,\n",
    "                         fused=None):\n",
    "        # Forzar fused=False y foreach=False para evitar codepaths que usan _dynamo\n",
    "        return original_adam_init(\n",
    "            self, params, lr=lr, betas=betas, eps=eps,\n",
    "            weight_decay=weight_decay, amsgrad=amsgrad,\n",
    "            foreach=False,  # FORZADO\n",
    "            maximize=maximize, capturable=False,  # FORZADO\n",
    "            differentiable=False, fused=False  # FORZADO\n",
    "        )\n",
    "    \n",
    "    torch.optim.Adam.__init__ = patched_adam_init\n",
    "    print(\"‚úÖ torch.optim.Adam parcheado\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error aplicando workaround: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"WORKAROUND AGRESIVO APLICADO\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nüìã M√≥dulos parcheados:\")\n",
    "print(\"   - torch._compile (reemplazado con dummy)\")\n",
    "print(\"   - torch.optim.Adam (forzado a modo legacy)\")\n",
    "print(\"   - Variables de entorno anti-dynamo configuradas\")\n",
    "print(\"\\n‚úÖ Ahora ejecuta el entrenamiento\")\n",
    "print(\"\\n‚ö†Ô∏è IMPORTANTE:\")\n",
    "print(\"   - Este workaround es TEMPORAL\")\n",
    "print(\"   - Rendimiento ser√° 10-15% m√°s lento\")\n",
    "print(\"   - Repara PyTorch cuando puedas:\")\n",
    "print(\"     pip uninstall -y torch torchvision torchaudio\")\n",
    "print(\"     pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121 --no-cache-dir\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dd5339",
   "metadata": {},
   "source": [
    "### ‚ö†Ô∏è INSTRUCCIONES CR√çTICAS\n",
    "\n",
    "**El workaround anterior NO funcionar√° si ya ejecutaste otras celdas que importaron torch.**\n",
    "\n",
    "**Para que funcione, DEBES:**\n",
    "\n",
    "1. **Reiniciar el Kernel** (bot√≥n ‚Üª arriba) - OBLIGATORIO\n",
    "2. **Ejecutar SOLO estas celdas en ORDEN:**\n",
    "   - Celda 1: Configuraci√≥n inicial\n",
    "   - Celda anterior: \"WORKAROUND AGRESIVO\"\n",
    "   - Celda de entrenamiento\n",
    "\n",
    "**NO ejecutes ninguna otra celda que importe torch antes del workaround.**\n",
    "\n",
    "Si ya ejecutaste otras celdas, el workaround no tendr√° efecto porque torch ya est√° corrupto en memoria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5fbe7d",
   "metadata": {},
   "source": [
    "### üîß SOLUCI√ìN DEFINITIVA: Reparar PyTorch Ahora\n",
    "\n",
    "**PyTorch est√° muy corrupto** (faltan m√≥dulos `_dynamo`, `_sympy`, etc.). El workaround es temporal y limitado.\n",
    "\n",
    "**La √∫nica soluci√≥n real es reinstalar PyTorch limpiamente.**\n",
    "\n",
    "Ejecuta la siguiente celda para hacerlo AUTOM√ÅTICAMENTE (tarda ~5 minutos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77de2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== REPARACI√ìN DEFINITIVA DE PYTORCH ==========\n",
    "# Esta celda SOLUCIONA el problema permanentemente\n",
    "# Reinstala PyTorch limpiamente sin m√≥dulos corruptos\n",
    "# ======================================================\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "import time\n",
    "\n",
    "print(\"üîß REPARACI√ìN DEFINITIVA DE PYTORCH\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\n‚è±Ô∏è Tiempo estimado: 4-6 minutos\")\n",
    "print(\"üìä Progreso: Se mostrar√° en tiempo real\\n\")\n",
    "\n",
    "# Usar el Python del kernel actual\n",
    "python_exe = sys.executable\n",
    "pip_cmd = f'\"{python_exe}\" -m pip'\n",
    "\n",
    "# Comandos de reparaci√≥n completa\n",
    "steps = [\n",
    "    {\n",
    "        'name': 'Desinstalar PyTorch corrupto',\n",
    "        'cmd': f'{pip_cmd} uninstall -y torch torchvision torchaudio torch-cuda torch-tensorrt triton',\n",
    "        'timeout': 60\n",
    "    },\n",
    "    {\n",
    "        'name': 'Limpiar cach√©s pip',\n",
    "        'cmd': f'{pip_cmd} cache purge',\n",
    "        'timeout': 30\n",
    "    },\n",
    "    {\n",
    "        'name': 'Reinstalar PyTorch limpio (CUDA 12.1)',\n",
    "        'cmd': f'{pip_cmd} install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121 --no-cache-dir --force-reinstall',\n",
    "        'timeout': 300\n",
    "    }\n",
    "]\n",
    "\n",
    "success_count = 0\n",
    "total_steps = len(steps)\n",
    "\n",
    "for i, step in enumerate(steps, 1):\n",
    "    print(f\"\\n[{i}/{total_steps}] {step['name']}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            step['cmd'],\n",
    "            shell=True,\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=step['timeout']\n",
    "        )\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        \n",
    "        # Mostrar solo l√≠neas importantes\n",
    "        if result.stdout:\n",
    "            for line in result.stdout.split('\\n'):\n",
    "                if any(kw in line.lower() for kw in [\n",
    "                    'successfully', 'installing', 'uninstalling',\n",
    "                    'downloading', 'collecting', 'requirement'\n",
    "                ]):\n",
    "                    print(line)\n",
    "        \n",
    "        if result.returncode == 0 or (i == 1 and 'not installed' in result.stdout.lower()):\n",
    "            print(f\"‚úÖ Completado en {elapsed:.1f}s\")\n",
    "            success_count += 1\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Completado con warnings ({elapsed:.1f}s)\")\n",
    "            if result.stderr and len(result.stderr) < 500:\n",
    "                print(f\"Detalles: {result.stderr}\")\n",
    "            \n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(f\"‚ùå Timeout despu√©s de {step['timeout']}s\")\n",
    "        print(\"   Intenta ejecutar manualmente desde terminal\")\n",
    "        break\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        break\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "\n",
    "if success_count == total_steps:\n",
    "    print(\"‚úÖ ¬°REPARACI√ìN COMPLETADA EXITOSAMENTE!\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nüîÑ SIGUIENTE PASO OBLIGATORIO:\")\n",
    "    print(\"   1. Haz clic en 'Restart' (bot√≥n ‚Üª arriba)\")\n",
    "    print(\"   2. Ejecuta la celda de verificaci√≥n de PyTorch\")\n",
    "    print(\"   3. Deber√≠as ver: ‚úÖ M√≥dulo _dynamo.guards: OK\")\n",
    "    print(\"   4. ¬°Listo para entrenar!\")\n",
    "    print(\"\\nüìã Para verificar manualmente:\")\n",
    "    print(\"   python -c \\\"import torch; from torch._C._dynamo.guards import GlobalStateGuard; print('OK')\\\"\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è REPARACI√ìN INCOMPLETA\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\n   Completados: {success_count}/{total_steps} pasos\")\n",
    "    print(\"\\nüìã SOLUCI√ìN MANUAL:\")\n",
    "    print(\"   Abre terminal (Ctrl+√ë) y ejecuta:\")\n",
    "    print(\"   conda activate pokeenv\")\n",
    "    for step in steps:\n",
    "        print(f\"   {step['cmd'].replace(pip_cmd, 'pip')}\")\n",
    "\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efa7fbe",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ RESUMEN: ¬øQu√© hacer con el error de PyTorch?\n",
    "\n",
    "Tu PyTorch est√° **muy corrupto** (faltan m√≥dulos internos cr√≠ticos). Tienes **2 opciones**:\n",
    "\n",
    "### ‚úÖ **Opci√≥n 1: REPARACI√ìN DEFINITIVA (Recomendado)**\n",
    "\n",
    "**Ejecuta la celda anterior** ‚Üí Espera 5 min ‚Üí Reinicia kernel ‚Üí ¬°Listo!\n",
    "\n",
    "**Ventajas:**\n",
    "- ‚úÖ Soluci√≥n permanente\n",
    "- ‚úÖ Rendimiento √≥ptimo\n",
    "- ‚úÖ No m√°s errores de _dynamo\n",
    "\n",
    "**Desventajas:**\n",
    "- ‚è±Ô∏è Tarda ~5 minutos\n",
    "- üîÑ Requiere reiniciar kernel\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ö° **Opci√≥n 2: WORKAROUND TEMPORAL (Para emergencias)**\n",
    "\n",
    "Si necesitas entrenar **AHORA** y no puedes esperar:\n",
    "\n",
    "1. **Reinicia el kernel** (bot√≥n ‚Üª)\n",
    "2. Ejecuta SOLO estas celdas EN ORDEN:\n",
    "   - Celda 1: Configuraci√≥n inicial  \n",
    "   - Celda \"WORKAROUND AGRESIVO\"\n",
    "   - Celda de entrenamiento\n",
    "3. **NO ejecutes** ninguna otra celda antes\n",
    "\n",
    "**Ventajas:**\n",
    "- ‚ö° Funciona inmediatamente\n",
    "- üöÄ Permite entrenar mientras reparas en paralelo\n",
    "\n",
    "**Desventajas:**\n",
    "- ‚ö†Ô∏è Temporal (cada vez que reinicies el kernel, debes reaplicarlo)\n",
    "- üìâ Rendimiento 10-15% m√°s lento\n",
    "- üêõ Puede fallar con algunos features avanzados\n",
    "\n",
    "---\n",
    "\n",
    "### üí° **Mi Recomendaci√≥n**\n",
    "\n",
    "**EJECUTA LA REPARACI√ìN DEFINITIVA** (celda anterior). Son solo 5 minutos y solucionar√°s el problema para siempre.\n",
    "\n",
    "Mientras esperas, puedes:\n",
    "- ‚òï Tomar un caf√©\n",
    "- üìñ Leer la documentaci√≥n\n",
    "- üéÆ Probar `run_pretrained_interactive.py` manualmente\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30026b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recargado: v2.red_gym_env_v2\n",
      "Recargado: advanced_agents.features\n",
      "Recargado: advanced_agents.wrappers\n",
      "Recargado: advanced_agents.base\n",
      "Recargado: advanced_agents.train_agents\n",
      "Recargado: advanced_agents.combat_apex_agent\n",
      "Recargado: advanced_agents.puzzle_speed_agent\n",
      "Recargado: advanced_agents.hybrid_sage_agent\n",
      "Recargado: advanced_agents.transition_models\n"
     ]
    }
   ],
   "source": [
    "# --- RELOAD MODULES ---\n",
    "def reload_modules():\n",
    "    modules_to_reload = [\n",
    "        'v2.red_gym_env_v2',\n",
    "        'advanced_agents.features',\n",
    "        'advanced_agents.wrappers',\n",
    "        'advanced_agents.base',\n",
    "        'advanced_agents.train_agents',\n",
    "        'advanced_agents.combat_apex_agent',\n",
    "        'advanced_agents.puzzle_speed_agent',\n",
    "        'advanced_agents.hybrid_sage_agent',\n",
    "        'advanced_agents.transition_models'\n",
    "    ]\n",
    "    for mod_name in modules_to_reload:\n",
    "        if mod_name in sys.modules:\n",
    "            try:\n",
    "                importlib.reload(sys.modules[mod_name])\n",
    "                print(f\"Recargado: {mod_name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"No se pudo recargar {mod_name}: {e}\")\n",
    "\n",
    "reload_modules()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaed01c",
   "metadata": {},
   "source": [
    "## 2. Recarga de m√≥dulos\n",
    "Permite refrescar los m√≥dulos clave de `advanced_agents` y del entorno RedGym cada vez que hagas cambios en el c√≥digo fuente sin tener que reiniciar el kernel. Ejecuta esta celda si modificas archivos Python relacionados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0901eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copiar events.json si es necesario\n",
    "events_source = os.path.join(project_path, 'baselines', 'events.json')\n",
    "events_dest = os.path.join(project_path, 'events.json')\n",
    "if os.path.exists(events_source) and not os.path.exists(events_dest):\n",
    "    shutil.copy(events_source, events_dest)\n",
    "    print(f\"Copiado events.json a {events_dest}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eaf1ae3",
   "metadata": {},
   "source": [
    "## 3. Sincronizaci√≥n de `events.json`\n",
    "Garantiza que el archivo de eventos requerido por PyBoy est√© disponible en la ra√≠z del proyecto copi√°ndolo desde `baselines/events.json` cuando falta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b0d2b4",
   "metadata": {},
   "source": [
    "## 4. Utilidades de entrenamiento\n",
    "Define el registro de agentes, valida que existan los archivos `.state`, construye las configuraciones de entorno y expone `train_single_run`/`train_plan`, que son los puntos de entrada para disparar los entrenamientos desde las celdas siguientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f060908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import shutil\n",
    "import types\n",
    "import importlib\n",
    "from typing import Dict, Iterable, List, Optional\n",
    "import os\n",
    "\n",
    "from gymnasium import spaces\n",
    "\n",
    "try:\n",
    "    from advanced_agents.train_agents import _base_env_config\n",
    "    from advanced_agents.combat_apex_agent import CombatApexAgent, CombatAgentConfig\n",
    "    from advanced_agents.puzzle_speed_agent import PuzzleSpeedAgent, PuzzleAgentConfig\n",
    "    from advanced_agents.hybrid_sage_agent import HybridSageAgent, HybridAgentConfig\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è ERROR DE IMPORTACI√ìN: {e}\")\n",
    "    raise e\n",
    "except OSError as e:\n",
    "    print(f\"‚ö†Ô∏è ERROR CR√çTICO DE PYTORCH: {e}\")\n",
    "    if \"126\" in str(e) or \"caffe2_nvrtc.dll\" in str(e):\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"   ¬°TU INSTALACI√ìN DE PYTORCH EST√Å ROTA!\")\n",
    "        print(\"   El kernel tiene archivos bloqueados o la versi√≥n es incompatible.\")\n",
    "        print(\"   \")\n",
    "        print(\"   SOLUCI√ìN DEFINITIVA:\")\n",
    "        print(\"   1. Abre la terminal (Ctrl+√ë)\")\n",
    "        print(\"   2. Ejecuta: ./repair_torch.ps1\")\n",
    "        print(\"   3. Reinicia el Kernel (Bot√≥n Restart ‚Üª)\")\n",
    "        print(\"=\"*60 + \"\\n\")\n",
    "    raise e\n",
    "\n",
    "# --- Cargar escenarios ---\n",
    "SCENARIO_PATH = os.path.join(project_path, 'gym_scenarios', 'scenarios.json')\n",
    "with open(SCENARIO_PATH, 'r') as f:\n",
    "    scenarios_data = json.load(f)\n",
    "\n",
    "SCENARIOS: Dict[str, Dict] = {scenario['id']: scenario for scenario in scenarios_data['scenarios']}\n",
    "\n",
    "AGENT_REGISTRY = {\n",
    "    'combat': {\n",
    "        'agent_cls': CombatApexAgent,\n",
    "        'config_cls': CombatAgentConfig,\n",
    "        'default_phase': 'battle'\n",
    "    },\n",
    "    'puzzle': {\n",
    "        'agent_cls': PuzzleSpeedAgent,\n",
    "        'config_cls': PuzzleAgentConfig,\n",
    "        'default_phase': 'puzzle'\n",
    "    },\n",
    "    'hybrid': {\n",
    "        'agent_cls': HybridSageAgent,\n",
    "        'config_cls': HybridAgentConfig,\n",
    "        'default_phase': 'battle'\n",
    "    }\n",
    "}\n",
    "\n",
    "MODELS_DIR = os.path.join(project_path, 'models_local')\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "\n",
    "def resolve_phase(scenario_id: str, phase_name: Optional[str]) -> Dict:\n",
    "    scenario = SCENARIOS.get(scenario_id)\n",
    "    if scenario is None:\n",
    "        raise ValueError(f\"Escenario {scenario_id} no encontrado en {SCENARIO_PATH}\")\n",
    "    target_phase = phase_name or AGENT_REGISTRY['combat']['default_phase']\n",
    "    selected_phase = next((p for p in scenario['phases'] if p['name'] == target_phase), None)\n",
    "    if selected_phase is None:\n",
    "        raise ValueError(f\"Fase {target_phase} no encontrada en el escenario {scenario_id}\")\n",
    "    return selected_phase\n",
    "\n",
    "def ensure_state_file(state_file_path: str) -> str:\n",
    "    abs_path = os.path.join(project_path, state_file_path) if not os.path.isabs(state_file_path) else state_file_path\n",
    "    if not os.path.exists(abs_path):\n",
    "        raise FileNotFoundError(\n",
    "            f\"No se encontr√≥ el archivo de estado requerido: {abs_path}. \"\n",
    "            \"Genera los .state con generate_gym_states.py o ajusta la ruta.\"\n",
    "        )\n",
    "    return abs_path\n",
    "\n",
    "def build_env_overrides(state_file_path: str, headless: bool) -> Dict:\n",
    "    return {\n",
    "        'init_state': state_file_path,\n",
    "        'headless': headless,\n",
    "        'save_video': False,\n",
    "        'gb_path': os.path.join(project_path, 'PokemonRed.gb'),\n",
    "        'session_path': os.path.join(project_path, 'sessions', f\"local_{os.path.basename(state_file_path)}\"),\n",
    "        'render_mode': 'rgb_array' if headless else 'human',\n",
    "        'fast_video': headless\n",
    "    }\n",
    "\n",
    "def _patch_callbacks(agent, additional_callbacks: Optional[List] = None):\n",
    "    base_callbacks_method = agent.extra_callbacks\n",
    "\n",
    "    def _patched_callbacks(self):\n",
    "        callbacks = list(base_callbacks_method())\n",
    "        if additional_callbacks:\n",
    "            callbacks.extend(additional_callbacks)\n",
    "        return callbacks\n",
    "\n",
    "    agent.extra_callbacks = types.MethodType(_patched_callbacks, agent)\n",
    "\n",
    "def train_single_run(\n",
    "    agent_key: str,\n",
    "    scenario_id: str,\n",
    "    phase_name: str,\n",
    "    total_timesteps: int = 500_000,\n",
    "    headless: bool = False,\n",
    "    additional_callbacks: Optional[List] = None\n",
    "):\n",
    "    registry_entry = AGENT_REGISTRY.get(agent_key)\n",
    "    if registry_entry is None:\n",
    "        raise ValueError(f\"Agente desconocido: {agent_key}\")\n",
    "\n",
    "    phase = resolve_phase(scenario_id, phase_name)\n",
    "    state_file_path = ensure_state_file(phase['state_file'])\n",
    "\n",
    "    env_overrides = build_env_overrides(state_file_path, headless=headless)\n",
    "    config = registry_entry['config_cls'](\n",
    "        env_config=_base_env_config(env_overrides),\n",
    "        total_timesteps=total_timesteps\n",
    "    )\n",
    "\n",
    "    agent = registry_entry['agent_cls'](config)\n",
    "\n",
    "    env_for_check = agent.make_env()\n",
    "    obs_space = getattr(env_for_check, 'observation_space', None)\n",
    "    if isinstance(obs_space, spaces.Dict):\n",
    "        print(\"Observaci√≥n Dict detectada -> MultiInputPolicy\")\n",
    "        agent.policy_name = types.MethodType(lambda self: \"MultiInputPolicy\", agent)\n",
    "    env_for_check.close()\n",
    "\n",
    "    if additional_callbacks:\n",
    "        _patch_callbacks(agent, additional_callbacks)\n",
    "\n",
    "    print(\n",
    "        f\"\\n=== Entrenando {agent_key.upper()} en {scenario_id} ({phase_name}) por {total_timesteps:,} pasos ===\")\n",
    "    runtime = agent.train()\n",
    "\n",
    "    agent_dir = os.path.join(MODELS_DIR, agent_key)\n",
    "    os.makedirs(agent_dir, exist_ok=True)\n",
    "    model_path = os.path.join(agent_dir, f\"{scenario_id}_{phase_name}.zip\")\n",
    "    runtime.model.save(model_path)\n",
    "    print(f\"Modelo guardado en {model_path}\")\n",
    "\n",
    "    return runtime\n",
    "\n",
    "def train_plan(\n",
    "    agent_key: str,\n",
    "    plan: List[Dict],\n",
    "    default_timesteps: int = 500_000,\n",
    "    headless: bool = False,\n",
    "    callback_factory: Optional[callable] = None\n",
    ") -> Dict[tuple, object]:\n",
    "    results = {}\n",
    "    total_runs = len(plan)\n",
    "    for run_idx, entry in enumerate(plan, start=1):\n",
    "        scenario_id = entry['scenario']\n",
    "        phase_name = entry.get('phase') or AGENT_REGISTRY[agent_key]['default_phase']\n",
    "        run_timesteps = entry.get('timesteps', default_timesteps)\n",
    "        callbacks = None\n",
    "        if callback_factory is not None:\n",
    "            callbacks = callback_factory(entry)\n",
    "        print(f\"\\n>>> [{agent_key.upper()}] Ejecuci√≥n {run_idx}/{total_runs}\")\n",
    "        runtime = train_single_run(\n",
    "            agent_key=agent_key,\n",
    "            scenario_id=scenario_id,\n",
    "            phase_name=phase_name,\n",
    "            total_timesteps=run_timesteps,\n",
    "            headless=headless,\n",
    "            additional_callbacks=callbacks\n",
    "        )\n",
    "        results[(scenario_id, phase_name)] = runtime\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e0dc9a",
   "metadata": {},
   "source": [
    "## 5. Planes de entrenamiento\n",
    "Ajusta aqu√≠ qu√© escenarios, fases y pasos quieres cubrir para cada agente. Usa esto como checklist antes de lanzar ejecuciones largas; puedes sobreescribir timesteps por fila y alternar `headless` para ver la ventana del emulador."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c64a9ad",
   "metadata": {},
   "source": [
    "### Configura planes de entrenamiento locales\n",
    "Especifica los escenarios, fases y timesteps que quieres para cada agente. Puedes ejecutar cada bloque por separado y combinar headless=True/False seg√∫n quieras ver la ventana del emulador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18da45a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTA: Para pruebas r√°pidas con pocos pasos (ej. 200), considera reducir n_steps\n",
    "# en la configuraci√≥n del agente, ya que PPO hace rollouts completos de n_steps=1024 por defecto.\n",
    "# Para entrenamiento real, usa valores como 40_000+ timesteps.\n",
    "\n",
    "combat_plan_local = [\n",
    "    {\"scenario\": \"pewter_brock\", \"phase\": \"battle\", \"timesteps\": 500_000},\n",
    "    # {\"scenario\": \"cerulean_misty\", \"phase\": \"battle\", \"timesteps\": 50_000},\n",
    "]\n",
    "\n",
    "puzzle_plan_local = [\n",
    "    {\"scenario\": \"pewter_brock\", \"phase\": \"puzzle\", \"timesteps\": 500_000},\n",
    "    # {\"scenario\": \"cerulean_misty\", \"phase\": \"puzzle\", \"timesteps\": 50_000},\n",
    "]\n",
    "\n",
    "hybrid_plan_local = [\n",
    "    {\"scenario\": \"pewter_brock\", \"phase\": \"battle\", \"timesteps\": 500_000},\n",
    "    # {\"scenario\": \"vermillion_lt_surge\", \"phase\": \"battle\", \"timesteps\": 60_000},\n",
    "]\n",
    "\n",
    "DEFAULT_TIMESTEPS_LOCAL = 500_000\n",
    "DEFAULT_HEADLESS_LOCAL = False  # Cambia a True si no necesitas la ventana SDL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1066e2c",
   "metadata": {},
   "source": [
    "## 6. Ejecutar plan de combate\n",
    "\n",
    "**IMPORTANTE**: Si tu entrenamiento anterior mostr√≥ `value_loss > 1000` o `explained_variance < 0.1`, el modelo **no aprendi√≥ correctamente**. \n",
    "\n",
    "**S√≠ntomas de entrenamiento fallido:**\n",
    "- value_loss = 3200 (deber√≠a estar cerca de 0)\n",
    "- explained_variance = 0.036 (deber√≠a ser >0.5)\n",
    "- Reward constante en evaluaci√≥n\n",
    "- Episodios terminan en timeout sin progreso\n",
    "\n",
    "**Soluci√≥n**: La siguiente celda usa par√°metros **estabilizados** autom√°ticamente. Solo ejec√∫tala para re-entrenar con configuraci√≥n robusta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0ad093",
   "metadata": {},
   "source": [
    "### ‚úÖ Verificaci√≥n Pre-Entrenamiento\n",
    "\n",
    "**Antes de ejecutar cualquier celda de entrenamiento, verifica:**\n",
    "\n",
    "1. **PyTorch con GPU funciona** (ejecuta la celda de verificaci√≥n arriba)\n",
    "2. **Los archivos .state existen** en `sessions/`\n",
    "3. **Tienes espacio en disco** (m√≠nimo 5GB libre)\n",
    "4. **El archivo `events.json`** est√° en la ra√≠z del proyecto\n",
    "\n",
    "**Problemas comunes y soluciones:**\n",
    "\n",
    "| Error | Causa | Soluci√≥n |\n",
    "|-------|-------|----------|\n",
    "| `ModuleNotFoundError: advanced_agents` | Paths incorrectos | Ejecuta celda de reload_modules |\n",
    "| `FileNotFoundError: .state` | Falta archivo de estado | Ejecuta `generate_gym_states.py` o verifica rutas |\n",
    "| `value_loss > 1000` | Hiperpar√°metros incorrectos | Usa la celda de \"Entrenamiento Estable\" |\n",
    "| `WinError 126` | PyTorch corrupto | Ejecuta `repair_torch.ps1` desde terminal |\n",
    "| Kernel crash | Conflicto OpenMP | Verifica que `KMP_DUPLICATE_LIB_OK=TRUE` est√© configurado |\n",
    "\n",
    "**Si algo falla durante el entrenamiento:**\n",
    "- Revisa los logs completos (scroll arriba en el output de la celda)\n",
    "- Busca el primer error (no el √∫ltimo)\n",
    "- Verifica que `headless=True` para entrenamientos largos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb3cfd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç DIAGN√ìSTICO DEL SISTEMA\n",
      "============================================================\n",
      "‚ùå Error con PyTorch: No module named 'tor√ách'\n",
      "\n",
      "============================================================\n",
      "DEPENDENCIAS CR√çTICAS:\n",
      "‚úÖ stable_baselines3\n",
      "‚úÖ gymnasium\n",
      "‚úÖ pyboy\n",
      "‚úÖ numpy\n",
      "‚úÖ pandas\n",
      "\n",
      "============================================================\n",
      "ARCHIVOS DE ESTADO (.state):\n",
      "‚úÖ Encontrados 5 archivos .state:\n",
      "   - interactive_pewter_battle.state\n",
      "   - local_gym_scenario.state\n",
      "   - local_interactive_pewter_battle.state\n",
      "   - local_pewter_battle.state\n",
      "   - local_pewter_puzzle.state\n",
      "\n",
      "============================================================\n",
      "ARCHIVO events.json:\n",
      "‚úÖ c:\\Users\\javi1\\Documents\\repos_git\\TEL351-PokemonRed\\events.json\n",
      "\n",
      "============================================================\n",
      "ESPACIO EN DISCO:\n",
      "‚úÖ Libre: 2 GB\n",
      "‚ö†Ô∏è Poco espacio. Se recomienda >5GB para checkpoints\n",
      "\n",
      "============================================================\n",
      "M√ìDULOS ADVANCED_AGENTS:\n",
      "‚úÖ advanced_agents importado correctamente\n",
      "\n",
      "============================================================\n",
      "CONFIGURACI√ìN OPENMP:\n",
      "‚úÖ KMP_DUPLICATE_LIB_OK = TRUE\n",
      "\n",
      "============================================================\n",
      "RESULTADO FINAL:\n",
      "‚ö†Ô∏è PROBLEMAS DETECTADOS:\n",
      "   - Poco espacio en disco\n",
      "\n",
      "Corrige los errores antes de entrenar.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ==================== DIAGN√ìSTICO PRE-ENTRENAMIENTO ====================\n",
    "# Ejecuta esta celda ANTES de entrenar para detectar problemas\n",
    "# =========================================================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"üîç DIAGN√ìSTICO DEL SISTEMA\\n\" + \"=\"*60)\n",
    "\n",
    "# 1. Verificar PyTorch y GPU\n",
    "try:\n",
    "    import tor√ách\n",
    "    print(f\"‚úÖ PyTorch: {torch.__version__}\")\n",
    "    print(f\"‚úÖ CUDA disponible: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è Usando CPU (entrenamiento ser√° MUY lento)\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error con PyTorch: {e}\")\n",
    "\n",
    "# 2. Verificar m√≥dulos cr√≠ticos\n",
    "modulos_criticos = [\n",
    "    'stable_baselines3',\n",
    "    'gymnasium',\n",
    "    'pyboy',\n",
    "    'numpy',\n",
    "    'pandas'\n",
    "]\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"DEPENDENCIAS CR√çTICAS:\")\n",
    "for modulo in modulos_criticos:\n",
    "    try:\n",
    "        __import__(modulo)\n",
    "        print(f\"‚úÖ {modulo}\")\n",
    "    except ImportError:\n",
    "        print(f\"‚ùå {modulo} - FALTA (ejecuta: pip install {modulo})\")\n",
    "\n",
    "# 3. Verificar archivos de estado\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ARCHIVOS DE ESTADO (.state):\")\n",
    "sessions_dir = Path(project_path) / 'sessions'\n",
    "if sessions_dir.exists():\n",
    "    state_files = list(sessions_dir.glob('*.state'))\n",
    "    if state_files:\n",
    "        print(f\"‚úÖ Encontrados {len(state_files)} archivos .state:\")\n",
    "        for f in state_files[:5]:  # Mostrar solo los primeros 5\n",
    "            print(f\"   - {f.name}\")\n",
    "        if len(state_files) > 5:\n",
    "            print(f\"   ... y {len(state_files) - 5} m√°s\")\n",
    "    else:\n",
    "        print(\"‚ùå No hay archivos .state en sessions/\")\n",
    "        print(\"   Soluci√≥n: Ejecuta generate_gym_states.py o run_pretrained_interactive.py\")\n",
    "else:\n",
    "    print(\"‚ùå Directorio sessions/ no existe\")\n",
    "\n",
    "# 4. Verificar events.json\n",
    "events_file = Path(project_path) / 'events.json'\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ARCHIVO events.json:\")\n",
    "if events_file.exists():\n",
    "    print(f\"‚úÖ {events_file}\")\n",
    "else:\n",
    "    print(\"‚ùå events.json no encontrado en ra√≠z del proyecto\")\n",
    "    print(\"   Soluci√≥n: La celda de sincronizaci√≥n lo copiar√° autom√°ticamente\")\n",
    "\n",
    "# 5. Verificar espacio en disco\n",
    "import shutil\n",
    "total, used, free = shutil.disk_usage(project_path)\n",
    "free_gb = free // (2**30)\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"ESPACIO EN DISCO:\")\n",
    "print(f\"‚úÖ Libre: {free_gb} GB\")\n",
    "if free_gb < 5:\n",
    "    print(\"‚ö†Ô∏è Poco espacio. Se recomienda >5GB para checkpoints\")\n",
    "\n",
    "# 6. Verificar advanced_agents\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"M√ìDULOS ADVANCED_AGENTS:\")\n",
    "try:\n",
    "    from advanced_agents.combat_apex_agent import CombatApexAgent\n",
    "    from advanced_agents.train_agents import _base_env_config\n",
    "    print(\"‚úÖ advanced_agents importado correctamente\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error importando advanced_agents: {e}\")\n",
    "    print(\"   Soluci√≥n: Ejecuta la celda de reload_modules arriba\")\n",
    "\n",
    "# 7. Verificar configuraci√≥n OpenMP\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"CONFIGURACI√ìN OPENMP:\")\n",
    "if os.environ.get(\"KMP_DUPLICATE_LIB_OK\") == \"TRUE\":\n",
    "    print(\"‚úÖ KMP_DUPLICATE_LIB_OK = TRUE\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è KMP_DUPLICATE_LIB_OK no configurado (puede causar crashes)\")\n",
    "    os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "    print(\"   Configurado autom√°ticamente\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"RESULTADO FINAL:\")\n",
    "\n",
    "# Resumen\n",
    "errores = []\n",
    "if not torch.cuda.is_available():\n",
    "    errores.append(\"GPU no disponible\")\n",
    "if not (sessions_dir.exists() and list(sessions_dir.glob('*.state'))):\n",
    "    errores.append(\"Faltan archivos .state\")\n",
    "if free_gb < 5:\n",
    "    errores.append(\"Poco espacio en disco\")\n",
    "\n",
    "if not errores:\n",
    "    print(\"üéâ ¬°TODO LISTO PARA ENTRENAR!\")\n",
    "    print(\"\\nPuedes ejecutar la siguiente celda de entrenamiento.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è PROBLEMAS DETECTADOS:\")\n",
    "    for error in errores:\n",
    "        print(f\"   - {error}\")\n",
    "    print(\"\\nCorrige los errores antes de entrenar.\")\n",
    "\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bb47a7",
   "metadata": {},
   "source": [
    "### üöÄ Entrenamiento Simplificado (Recomendado)\n",
    "\n",
    "Esta celda ejecuta el entrenamiento con configuraci√≥n robusta y manejo de errores autom√°tico.\n",
    "\n",
    "**Caracter√≠sticas:**\n",
    "- ‚úÖ Detecta autom√°ticamente el mejor estado .state disponible\n",
    "- ‚úÖ Valida que PyTorch funcione antes de empezar\n",
    "- ‚úÖ Guarda checkpoints cada 10k steps\n",
    "- ‚úÖ Muestra progreso con barra interactiva\n",
    "- ‚úÖ Manejo autom√°tico de errores comunes\n",
    "\n",
    "**Personalizaci√≥n:**\n",
    "- `timesteps`: 40,000 (prueba), 500,000 (entrenamiento serio)\n",
    "- `headless`: True (sin ventana), False (ver juego)\n",
    "- `num_envs`: 1-16 (seg√∫n tu CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a79cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "   üéÆ ENTRENAMIENTO DE COMBATE - CONFIGURACI√ìN ROBUSTA\n",
      "======================================================================\n",
      "\n",
      "1Ô∏è‚É£ Validando PyTorch...\n",
      "   ‚úÖ GPU: NVIDIA GeForce RTX 3050\n",
      "\n",
      "2Ô∏è‚É£ Buscando archivo de estado...\n",
      "   ‚úÖ Usando: interactive_pewter_battle.state\n",
      "\n",
      "3Ô∏è‚É£ Configurando entorno...\n",
      "   ‚úÖ Entorno configurado\n",
      "\n",
      "4Ô∏è‚É£ Creando agente...\n",
      "   ‚úÖ Usando: interactive_pewter_battle.state\n",
      "\n",
      "3Ô∏è‚É£ Configurando entorno...\n",
      "   ‚úÖ Entorno configurado\n",
      "\n",
      "4Ô∏è‚É£ Creando agente...\n",
      "   ‚ùå Error creando agente: No module named 'torch.utils._sympy'\n",
      "   ‚ùå Error creando agente: No module named 'torch.utils._sympy'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\javi1\\AppData\\Local\\Temp\\ipykernel_10104\\2970312569.py\", line 100, in train_combat_robust\n",
      "    agent = CombatApexAgent(agent_config)\n",
      "  File \"c:\\Users\\javi1\\Documents\\repos_git\\TEL351-PokemonRed\\advanced_agents\\combat_apex_agent.py\", line 36, in __init__\n",
      "    self.dynamics_optimizer = torch.optim.Adam(self.dynamics.parameters(), lr=config.aux_lr)\n",
      "  File \"c:\\Users\\javi1\\anaconda3\\envs\\pokeenv\\lib\\site-packages\\torch\\optim\\adam.py\", line 78, in __init__\n",
      "  File \"c:\\Users\\javi1\\anaconda3\\envs\\pokeenv\\lib\\site-packages\\torch\\optim\\optimizer.py\", line 371, in __init__\n",
      "  File \"c:\\Users\\javi1\\anaconda3\\envs\\pokeenv\\lib\\site-packages\\torch\\_compile.py\", line 27, in inner\n",
      "    import torch._dynamo\n",
      "  File \"c:\\Users\\javi1\\anaconda3\\envs\\pokeenv\\lib\\site-packages\\torch\\_dynamo\\__init__.py\", line 3, in <module>\n",
      "    from . import convert_frame, eval_frame, resume_execution\n",
      "  File \"c:\\Users\\javi1\\anaconda3\\envs\\pokeenv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 31, in <module>\n",
      "    from torch._dynamo.utils import CompileTimeInstructionCounter\n",
      "  File \"c:\\Users\\javi1\\anaconda3\\envs\\pokeenv\\lib\\site-packages\\torch\\_dynamo\\utils.py\", line 62, in <module>\n",
      "    import torch.fx.experimental.symbolic_shapes\n",
      "  File \"c:\\Users\\javi1\\anaconda3\\envs\\pokeenv\\lib\\site-packages\\torch\\fx\\experimental\\symbolic_shapes.py\", line 65, in <module>\n",
      "    from torch.utils._sympy.functions import (\n",
      "ModuleNotFoundError: No module named 'torch.utils._sympy'\n"
     ]
    }
   ],
   "source": [
    "# ==================== ENTRENAMIENTO SIMPLIFICADO Y ROBUSTO ====================\n",
    "# Ejecuta esta celda para entrenar con la mejor configuraci√≥n autom√°tica\n",
    "# ===============================================================================\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from advanced_agents.combat_apex_agent import CombatApexAgent, CombatAgentConfig\n",
    "\n",
    "# ======================== CONFIGURACI√ìN (Editable) ========================\n",
    "TIMESTEPS = 40_000          # Pasos de entrenamiento (40k = ~30min, 500k = ~4h)\n",
    "HEADLESS = True             # True = sin ventana (m√°s r√°pido), False = ver juego\n",
    "NUM_ENVS = 4                # Entornos paralelos (1-16, ajusta seg√∫n CPU)\n",
    "SCENARIO_ID = 'pewter_brock'\n",
    "PHASE_NAME = 'battle'\n",
    "# ==========================================================================\n",
    "\n",
    "def find_best_state_file():\n",
    "    \"\"\"Encuentra autom√°ticamente el mejor archivo .state disponible.\"\"\"\n",
    "    sessions_dir = Path(project_path) / 'sessions'\n",
    "    \n",
    "    # Prioridad de b√∫squeda\n",
    "    preferred_files = [\n",
    "        'interactive_pewter_battle.state',\n",
    "        'local_pewter_battle.state',\n",
    "        'local_gym_scenario.state',\n",
    "        'manual_save_*.state'\n",
    "    ]\n",
    "    \n",
    "    for pattern in preferred_files:\n",
    "        matches = list(sessions_dir.glob(pattern))\n",
    "        if matches:\n",
    "            # Retornar el m√°s reciente si hay varios\n",
    "            return max(matches, key=lambda p: p.stat().st_mtime)\n",
    "    \n",
    "    # Fallback: cualquier .state\n",
    "    all_states = list(sessions_dir.glob('*.state'))\n",
    "    if all_states:\n",
    "        return max(all_states, key=lambda p: p.stat().st_mtime)\n",
    "    \n",
    "    return None\n",
    "\n",
    "def train_combat_robust():\n",
    "    \"\"\"Entrenamiento con validaci√≥n completa y manejo de errores.\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"   üéÆ ENTRENAMIENTO DE COMBATE - CONFIGURACI√ìN ROBUSTA\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # 1. Validar PyTorch\n",
    "    print(\"1Ô∏è‚É£ Validando PyTorch...\")\n",
    "    if not torch.cuda.is_available():\n",
    "        print(\"   ‚ö†Ô∏è GPU no detectada. Entrenamiento ser√° LENTO.\")\n",
    "        response = input(\"   ¬øContinuar con CPU? (s/n): \")\n",
    "        if response.lower() != 's':\n",
    "            print(\"   ‚ùå Entrenamiento cancelado. Repara PyTorch primero.\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"   ‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    \n",
    "    # 2. Buscar archivo de estado\n",
    "    print(\"\\n2Ô∏è‚É£ Buscando archivo de estado...\")\n",
    "    state_file = find_best_state_file()\n",
    "    \n",
    "    if not state_file:\n",
    "        print(\"   ‚ùå No se encontraron archivos .state en sessions/\")\n",
    "        print(\"   Soluci√≥n: Ejecuta run_pretrained_interactive.py para generar estados\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"   ‚úÖ Usando: {state_file.name}\")\n",
    "    \n",
    "    # 3. Configurar entorno\n",
    "    print(\"\\n3Ô∏è‚É£ Configurando entorno...\")\n",
    "    try:\n",
    "        phase = resolve_phase(SCENARIO_ID, PHASE_NAME)\n",
    "        env_overrides = build_env_overrides(str(state_file), headless=HEADLESS)\n",
    "        base_config = _base_env_config(env_overrides)\n",
    "        print(\"   ‚úÖ Entorno configurado\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error configurando entorno: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # 4. Crear configuraci√≥n del agente\n",
    "    print(\"\\n4Ô∏è‚É£ Creando agente...\")\n",
    "    try:\n",
    "        agent_config = CombatAgentConfig(\n",
    "            env_config=base_config,\n",
    "            total_timesteps=TIMESTEPS,\n",
    "            learning_rate=1e-4,\n",
    "            n_steps=512,\n",
    "            batch_size=128,\n",
    "            gamma=0.998,\n",
    "            gae_lambda=0.95,\n",
    "            clip_range=0.1,\n",
    "            vf_coef=0.25,\n",
    "            ent_coef=0.01,\n",
    "            device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        )\n",
    "        \n",
    "        agent = CombatApexAgent(agent_config)\n",
    "        print(\"   ‚úÖ Agente creado\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error creando agente: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "    \n",
    "    # 5. Configurar pol√≠tica\n",
    "    print(\"\\n5Ô∏è‚É£ Configurando pol√≠tica...\")\n",
    "    try:\n",
    "        env_check = agent.make_env()\n",
    "        from gymnasium import spaces\n",
    "        import types\n",
    "        \n",
    "        if isinstance(env_check.observation_space, spaces.Dict):\n",
    "            agent.policy_name = types.MethodType(lambda self: \"MultiInputPolicy\", agent)\n",
    "            print(\"   ‚úÖ MultiInputPolicy (observaci√≥n Dict)\")\n",
    "        else:\n",
    "            print(\"   ‚úÖ CnnPolicy (observaci√≥n est√°ndar)\")\n",
    "        \n",
    "        env_check.close()\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è Error verificando pol√≠tica: {e}\")\n",
    "    \n",
    "    # 6. Entrenar\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"   üöÄ INICIANDO ENTRENAMIENTO\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"   Pasos: {TIMESTEPS:,}\")\n",
    "    print(f\"   Entornos: {NUM_ENVS}\")\n",
    "    print(f\"   Modo: {'Headless' if HEADLESS else 'Con ventana'}\")\n",
    "    print(f\"   Device: {agent_config.device}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    try:\n",
    "        runtime = agent.train()\n",
    "        print(\"\\n   ‚úÖ Entrenamiento completado exitosamente\")\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n   ‚è∏Ô∏è Entrenamiento interrumpido por usuario\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"\\n   ‚ùå Error durante entrenamiento: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "    \n",
    "    # 7. Guardar modelo\n",
    "    print(\"\\n7Ô∏è‚É£ Guardando modelo...\")\n",
    "    save_dir = Path(MODELS_DIR) / 'combat'\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "    save_path = save_dir / f\"{SCENARIO_ID}_{PHASE_NAME}_robust.zip\"\n",
    "    \n",
    "    try:\n",
    "        runtime.model.save(str(save_path))\n",
    "        print(f\"   ‚úÖ Modelo guardado: {save_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error guardando: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # 8. Resumen\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"   ‚úÖ ENTRENAMIENTO FINALIZADO EXITOSAMENTE\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"   Modelo: {save_path.name}\")\n",
    "    print(f\"   Ubicaci√≥n: {save_path}\")\n",
    "    print(f\"\\n   üìä Revisa las m√©tricas:\")\n",
    "    print(f\"   - value_loss: Deber√≠a estar < 100\")\n",
    "    print(f\"   - explained_variance: Deber√≠a estar > 0.3\")\n",
    "    print(f\"\\n   üéÆ Para probar el modelo:\")\n",
    "    print(f\"   python run_combat_agent_interactive.py --scenario {SCENARIO_ID}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    return str(save_path)\n",
    "\n",
    "# EJECUTAR\n",
    "modelo_entrenado = train_combat_robust()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bd175e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "   ENTRENAMIENTO ESTABLE - COMBAT APEX AGENT\n",
      "   Escenario: pewter_brock | Fase: battle\n",
      "   Pasos: 500,000\n",
      "   Par√°metros: LR reducido, clipping conservador, gradientes limitados\n",
      "======================================================================\n",
      "\n",
      "‚ùå ERROR AL CREAR AGENTE: No module named 'torch.utils._sympy'\n",
      "\n",
      "‚ùå El entrenamiento fall√≥. Revisa los errores arriba.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\javi1\\AppData\\Local\\Temp\\ipykernel_10104\\1200321393.py\", line 41, in train_combat_stable\n",
      "    agent = CombatApexAgent(agent_config)\n",
      "  File \"c:\\Users\\javi1\\Documents\\repos_git\\TEL351-PokemonRed\\advanced_agents\\combat_apex_agent.py\", line 36, in __init__\n",
      "    self.dynamics_optimizer = torch.optim.Adam(self.dynamics.parameters(), lr=config.aux_lr)\n",
      "  File \"c:\\Users\\javi1\\anaconda3\\envs\\pokeenv\\lib\\site-packages\\torch\\optim\\adam.py\", line 78, in __init__\n",
      "  File \"c:\\Users\\javi1\\anaconda3\\envs\\pokeenv\\lib\\site-packages\\torch\\optim\\optimizer.py\", line 371, in __init__\n",
      "  File \"c:\\Users\\javi1\\anaconda3\\envs\\pokeenv\\lib\\site-packages\\torch\\_compile.py\", line 27, in inner\n",
      "    import torch._dynamo\n",
      "  File \"c:\\Users\\javi1\\anaconda3\\envs\\pokeenv\\lib\\site-packages\\torch\\_dynamo\\__init__.py\", line 3, in <module>\n",
      "    from . import convert_frame, eval_frame, resume_execution\n",
      "  File \"c:\\Users\\javi1\\anaconda3\\envs\\pokeenv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 31, in <module>\n",
      "    from torch._dynamo.utils import CompileTimeInstructionCounter\n",
      "  File \"c:\\Users\\javi1\\anaconda3\\envs\\pokeenv\\lib\\site-packages\\torch\\_dynamo\\utils.py\", line 62, in <module>\n",
      "    import torch.fx.experimental.symbolic_shapes\n",
      "  File \"c:\\Users\\javi1\\anaconda3\\envs\\pokeenv\\lib\\site-packages\\torch\\fx\\experimental\\symbolic_shapes.py\", line 65, in <module>\n",
      "    from torch.utils._sympy.functions import (\n",
      "ModuleNotFoundError: No module named 'torch.utils._sympy'\n"
     ]
    }
   ],
   "source": [
    "# ==================== ENTRENAMIENTO CON PAR√ÅMETROS ESTABLES ====================\n",
    "# Si tu entrenamiento anterior fall√≥ (value_loss alto), esta versi√≥n usa par√°metros\n",
    "# m√°s conservadores que garantizan convergencia.\n",
    "# =================================================================================\n",
    "\n",
    "from advanced_agents.combat_apex_agent import CombatApexAgent, CombatAgentConfig\n",
    "import torch\n",
    "\n",
    "def train_combat_stable(scenario_id='pewter_brock', phase_name='battle', timesteps=40_000):\n",
    "    \"\"\"Entrena CombatApexAgent con par√°metros estabilizados.\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"   ENTRENAMIENTO ESTABLE - COMBAT APEX AGENT\")\n",
    "    print(f\"   Escenario: {scenario_id} | Fase: {phase_name}\")\n",
    "    print(f\"   Pasos: {timesteps:,}\")\n",
    "    print(f\"   Par√°metros: LR reducido, clipping conservador, gradientes limitados\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # Configurar entorno\n",
    "    phase = resolve_phase(scenario_id, phase_name)\n",
    "    state_file_path = ensure_state_file(phase['state_file'])\n",
    "    env_overrides = build_env_overrides(state_file_path, headless=True)\n",
    "    base_config = _base_env_config(env_overrides)\n",
    "    \n",
    "    # Configuraci√≥n ESTABLE (par√°metros ajustados para evitar divergencia)\n",
    "    agent_config = CombatAgentConfig(\n",
    "        env_config=base_config,\n",
    "        total_timesteps=timesteps,\n",
    "        learning_rate=1e-4,      # M√°s conservador que 2.5e-4\n",
    "        n_steps=512,             # Actualizaciones m√°s frecuentes\n",
    "        batch_size=128,          # Batches m√°s peque√±os\n",
    "        gamma=0.998,             # Menos influencia del futuro\n",
    "        gae_lambda=0.95,\n",
    "        clip_range=0.1,          # Clipping m√°s estricto\n",
    "        vf_coef=0.25,            # Menos peso a la funci√≥n de valor\n",
    "        ent_coef=0.01,           # Entrop√≠a para exploraci√≥n\n",
    "        device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    )\n",
    "    \n",
    "    # Crear agente\n",
    "    try:\n",
    "        agent = CombatApexAgent(agent_config)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ERROR AL CREAR AGENTE: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "    \n",
    "    # Verificar espacio de observaciones\n",
    "    try:\n",
    "        env_check = agent.make_env()\n",
    "        from gymnasium import spaces\n",
    "        if isinstance(env_check.observation_space, spaces.Dict):\n",
    "            print(\"‚úÖ Observaci√≥n Dict detectada -> MultiInputPolicy\")\n",
    "            import types\n",
    "            agent.policy_name = types.MethodType(lambda self: \"MultiInputPolicy\", agent)\n",
    "        else:\n",
    "            print(\"‚úÖ Observaci√≥n est√°ndar detectada -> CnnPolicy\")\n",
    "        env_check.close()\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error verificando espacio de observaciones: {e}\")\n",
    "    \n",
    "    # Entrenar\n",
    "    print(f\"\\nüöÄ Iniciando entrenamiento estable...\")\n",
    "    try:\n",
    "        runtime = agent.train()\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ERROR DURANTE ENTRENAMIENTO: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "    \n",
    "    # Guardar\n",
    "    save_dir = os.path.join(MODELS_DIR, 'combat')\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    save_path = os.path.join(save_dir, f\"{scenario_id}_{phase_name}_stable.zip\")\n",
    "    \n",
    "    try:\n",
    "        runtime.model.save(save_path)\n",
    "        print(f\"\\n‚úÖ Modelo ESTABLE guardado en: {save_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ERROR AL GUARDAR MODELO: {e}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"\\nüìä Revisa los logs - deber√≠as ver:\")\n",
    "    print(f\"   - value_loss < 100 (idealmente < 10)\")\n",
    "    print(f\"   - explained_variance > 0.3 (mejorando hacia 0.7+)\")\n",
    "    print(f\"   - approx_kl < 0.05\")\n",
    "    \n",
    "    return save_path\n",
    "\n",
    "# EJECUTAR ENTRENAMIENTO ESTABLE\n",
    "try:\n",
    "    combat_model_stable = train_combat_stable(\n",
    "        scenario_id='pewter_brock',\n",
    "        phase_name='battle', \n",
    "        timesteps=500_000\n",
    "    )\n",
    "    \n",
    "    if combat_model_stable:\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"‚úÖ ENTRENAMIENTO COMPLETO\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"Modelo guardado en: {combat_model_stable}\")\n",
    "        print(f\"\\nüéÆ Para probarlo:\")\n",
    "        print(f\"python run_combat_agent_interactive.py --scenario pewter_brock --phase battle\")\n",
    "        print(f\"{'='*70}\")\n",
    "    else:\n",
    "        print(f\"\\n‚ùå El entrenamiento fall√≥. Revisa los errores arriba.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå ERROR CR√çTICO: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787f6bb1",
   "metadata": {},
   "source": [
    "## 7. Ejecutar plan de puzzles\n",
    "Corre el plan `puzzle_plan_local` usando `PuzzleSpeedAgent` y guarda salidas en `models_local/puzzle/`. √ötil para medir tiempos de navegaci√≥n y resoluci√≥n de puzzles previos al combate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c309e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> [PUZZLE] Ejecuci√≥n 1/1\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch.utils._sympy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m puzzle_runs_local \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_plan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43magent_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpuzzle\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpuzzle_plan_local\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefault_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEFAULT_TIMESTEPS_LOCAL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheadless\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEFAULT_HEADLESS_LOCAL\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[14], line 163\u001b[0m, in \u001b[0;36mtrain_plan\u001b[1;34m(agent_key, plan, default_timesteps, headless, callback_factory)\u001b[0m\n\u001b[0;32m    161\u001b[0m         callbacks \u001b[38;5;241m=\u001b[39m callback_factory(entry)\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m>>> [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00magent_key\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] Ejecuci√≥n \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_runs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 163\u001b[0m     runtime \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_single_run\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43magent_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43magent_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscenario_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscenario_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mphase_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mphase_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheadless\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheadless\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43madditional_callbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    171\u001b[0m     results[(scenario_id, phase_name)] \u001b[38;5;241m=\u001b[39m runtime\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "Cell \u001b[1;32mIn[14], line 122\u001b[0m, in \u001b[0;36mtrain_single_run\u001b[1;34m(agent_key, scenario_id, phase_name, total_timesteps, headless, additional_callbacks)\u001b[0m\n\u001b[0;32m    116\u001b[0m env_overrides \u001b[38;5;241m=\u001b[39m build_env_overrides(state_file_path, headless\u001b[38;5;241m=\u001b[39mheadless)\n\u001b[0;32m    117\u001b[0m config \u001b[38;5;241m=\u001b[39m registry_entry[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig_cls\u001b[39m\u001b[38;5;124m'\u001b[39m](\n\u001b[0;32m    118\u001b[0m     env_config\u001b[38;5;241m=\u001b[39m_base_env_config(env_overrides),\n\u001b[0;32m    119\u001b[0m     total_timesteps\u001b[38;5;241m=\u001b[39mtotal_timesteps\n\u001b[0;32m    120\u001b[0m )\n\u001b[1;32m--> 122\u001b[0m agent \u001b[38;5;241m=\u001b[39m \u001b[43mregistry_entry\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43magent_cls\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    124\u001b[0m env_for_check \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mmake_env()\n\u001b[0;32m    125\u001b[0m obs_space \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(env_for_check, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobservation_space\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\javi1\\Documents\\repos_git\\TEL351-PokemonRed\\advanced_agents\\puzzle_speed_agent.py:33\u001b[0m, in \u001b[0;36mPuzzleSpeedAgent.__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(config)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph_model \u001b[38;5;241m=\u001b[39m PuzzleGraphTransitionModel(grid_dim\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpatch_radius, iterations\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mgraph_iterations)\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph_optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maux_lr\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\javi1\\anaconda3\\envs\\pokeenv\\lib\\site-packages\\torch\\optim\\adam.py:78\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\javi1\\anaconda3\\envs\\pokeenv\\lib\\site-packages\\torch\\optim\\optimizer.py:371\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, params, defaults)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\javi1\\anaconda3\\envs\\pokeenv\\lib\\site-packages\\torch\\_compile.py:27\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m disable_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(fn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__dynamo_disable\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m disable_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 27\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\n\u001b[0;32m     29\u001b[0m     disable_fn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisable(fn, recursive)\n\u001b[0;32m     30\u001b[0m     fn\u001b[38;5;241m.\u001b[39m__dynamo_disable \u001b[38;5;241m=\u001b[39m disable_fn\n",
      "File \u001b[1;32mc:\\Users\\javi1\\anaconda3\\envs\\pokeenv\\lib\\site-packages\\torch\\_dynamo\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m convert_frame, eval_frame, resume_execution\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m list_backends, lookup_backend, register_backend\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallback\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m callback_handler, on_compile_end, on_compile_start\n",
      "File \u001b[1;32mc:\\Users\\javi1\\anaconda3\\envs\\pokeenv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py:31\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mguards\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GlobalStateGuard\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_compile_pg\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CompileTimeInstructionCounter\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_guards\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compile_context, CompileContext, CompileId, tracing\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_logging\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m structured\n",
      "File \u001b[1;32mc:\\Users\\javi1\\anaconda3\\envs\\pokeenv\\lib\\site-packages\\torch\\_dynamo\\utils.py:62\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_functorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_inductor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01minductor_config\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msymbolic_shapes\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pytree\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpytree\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m fx\n",
      "File \u001b[1;32mc:\\Users\\javi1\\anaconda3\\envs\\pokeenv\\lib\\site-packages\\torch\\fx\\experimental\\symbolic_shapes.py:65\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_guards\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ShapeGuard, Source, TracingContext\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_python_dispatch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_traceable_wrapper_subclass\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sympy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     66\u001b[0m     Application, FloorDiv, Mod, PythonMod, IsNonOverlappingAndDenseIndicator, CleanDiv, FloorToInt, CeilToInt\n\u001b[0;32m     67\u001b[0m )\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sympy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msolve\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m try_solve\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sympy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumbers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m int_oo\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch.utils._sympy'"
     ]
    }
   ],
   "source": [
    "puzzle_runs_local = train_plan(\n",
    "    agent_key='puzzle',\n",
    "    plan=puzzle_plan_local,\n",
    "    default_timesteps=DEFAULT_TIMESTEPS_LOCAL,\n",
    "    headless=DEFAULT_HEADLESS_LOCAL\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5b8c0e",
   "metadata": {},
   "source": [
    "## 8. Ejecutar plan h√≠brido\n",
    "Activa `HybridSageAgent` sobre los escenarios definidos en `hybrid_plan_local`, mezclando comportamientos de combate y navegaci√≥n y almacenando resultados en `models_local/hybrid/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c901491",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_runs_local = train_plan(\n",
    "    agent_key='hybrid',\n",
    "    plan=hybrid_plan_local,\n",
    "    default_timesteps=DEFAULT_TIMESTEPS_LOCAL,\n",
    "    headless=DEFAULT_HEADLESS_LOCAL\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d198425e",
   "metadata": {},
   "source": [
    "## 9. Guardado manual (opcional)\n",
    "Fragmento de ejemplo para guardar un modelo entrenado con un nombre personalizado. Solo √∫salo si traes a la sesi√≥n variables como `model`, `AGENT_TYPE`, `SCENARIO_ID` y `PHASE_NAME`; de lo contrario producir√° errores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e84f117",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AGENT_TYPE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m save_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels_local\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(save_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 4\u001b[0m save_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mAGENT_TYPE\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSCENARIO_ID\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPHASE_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39msave(save_path)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModelo guardado en \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'AGENT_TYPE' is not defined"
     ]
    }
   ],
   "source": [
    "# Guardar modelo\n",
    "save_dir = \"models_local\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "save_path = os.path.join(save_dir, f\"{AGENT_TYPE}_{SCENARIO_ID}_{PHASE_NAME}\")\n",
    "model.save(save_path)\n",
    "print(f\"Modelo guardado en {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7579e81b",
   "metadata": {},
   "source": [
    "## 10. Comparaci√≥n con Baseline (PPO v2)\n",
    "\n",
    "Esta secci√≥n permite comparar el desempe√±o de tus agentes entrenados (Combat, Puzzle, Hybrid) contra un baseline.\n",
    "\n",
    "**IMPORTANTE - Limitaciones de RAM (16GB):**\n",
    "- El modelo `poke_26214400.zip` (26M pasos) requiere >10GB solo para cargarlo\n",
    "- **Alternativa recomendada**: Entrenar tu propio baseline ligero (40k-100k pasos) en lugar de usar el modelo pesado\n",
    "- O simplemente evaluar solo tus modelos locales sin comparaci√≥n (ver celda siguiente)\n",
    "\n",
    "**Alternativa para comparar sin .zip pesado:**\n",
    "Puedes usar `run_pretrained_interactive.py` como baseline ejecut√°ndolo manualmente y registrando las m√©tricas, pero esta secci√≥n automatiza la evaluaci√≥n de **tus modelos** sin necesidad del baseline gigante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35bd7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from stable_baselines3 import PPO\n",
    "from v2.red_gym_env_v2 import RedGymEnv\n",
    "\n",
    "def load_baseline_model(path):\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"No se encontr√≥ el modelo baseline en: {path}\")\n",
    "        return None\n",
    "    try:\n",
    "        return PPO.load(path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error cargando baseline: {e}\")\n",
    "        return None\n",
    "\n",
    "def evaluate_agent_model(model, env, num_episodes=1):\n",
    "    \"\"\"Ejecuta episodios de evaluaci√≥n y retorna m√©tricas promedio.\"\"\"\n",
    "    rewards = []\n",
    "    steps = []\n",
    "    \n",
    "    for i in range(num_episodes):\n",
    "        # Manejar diferentes formatos de reset()\n",
    "        try:\n",
    "            reset_result = env.reset()\n",
    "            obs = reset_result[0] if isinstance(reset_result, tuple) else reset_result\n",
    "        except Exception as e:\n",
    "            print(f\"Error en reset: {e}\")\n",
    "            continue\n",
    "        \n",
    "        done = False\n",
    "        truncated = False\n",
    "        total_reward = 0\n",
    "        step_count = 0\n",
    "        max_steps = 5000  # L√≠mite de pasos por episodio\n",
    "        \n",
    "        while not done and not truncated and step_count < max_steps:\n",
    "            try:\n",
    "                # FIX: Asegurar que obs sea dict/array, no tupla\n",
    "                if isinstance(obs, tuple):\n",
    "                    obs = obs[0]\n",
    "                    \n",
    "                action, _ = model.predict(obs, deterministic=True)\n",
    "                step_result = env.step(action)\n",
    "                \n",
    "                # Manejar diferentes formatos de step()\n",
    "                if len(step_result) == 5:\n",
    "                    obs, reward, done, truncated, info = step_result\n",
    "                elif len(step_result) == 4:\n",
    "                    obs, reward, done, info = step_result\n",
    "                    truncated = False\n",
    "                else:\n",
    "                    raise ValueError(f\"Formato inesperado de step(): {len(step_result)} valores\")\n",
    "                \n",
    "                # FIX: Manejar VecEnv (arrays) vs Env est√°ndar (escalares)\n",
    "                if isinstance(done, (list, np.ndarray)):\n",
    "                    done = done[0] if len(done) > 0 else False\n",
    "                if isinstance(truncated, (list, np.ndarray)):\n",
    "                    truncated = truncated[0] if len(truncated) > 0 else False\n",
    "                if isinstance(reward, (list, np.ndarray)):\n",
    "                    reward = reward[0] if len(reward) > 0 else 0\n",
    "                \n",
    "                # Convertir reward a escalar\n",
    "                reward_scalar = float(reward.item() if hasattr(reward, 'item') else reward)\n",
    "                total_reward += reward_scalar\n",
    "                step_count += 1\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error en step {step_count}: {e}\")\n",
    "                break\n",
    "            \n",
    "        rewards.append(total_reward)\n",
    "        steps.append(step_count)\n",
    "        \n",
    "    return {\n",
    "        'mean_reward': np.mean(rewards) if rewards else 0,\n",
    "        'std_reward': np.std(rewards) if rewards else 0,\n",
    "        'mean_steps': np.mean(steps) if steps else 0\n",
    "    }\n",
    "\n",
    "def run_comparison_lightweight(plans_dict, baseline_path=None, headless=True, skip_baseline=False):\n",
    "    \"\"\"\n",
    "    Versi√≥n optimizada para RAM limitada (<=16GB con Windows ocupando 10GB).\n",
    "    skip_baseline=True: Solo eval√∫a tus modelos locales (recomendado para 16GB RAM)\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Cargar Baseline solo si se solicita y existe\n",
    "    baseline_model = None\n",
    "    if not skip_baseline and baseline_path:\n",
    "        print(f\"Intentando cargar modelo baseline desde: {baseline_path}\")\n",
    "        baseline_model = load_baseline_model(baseline_path)\n",
    "        if not baseline_model:\n",
    "            print(\"No se pudo cargar el baseline. Solo se evaluar√°n modelos locales.\")\n",
    "    else:\n",
    "        print(\"Modo sin baseline activado (ahorra ~10GB RAM)\")\n",
    "    \n",
    "    for agent_key, plan in plans_dict.items():\n",
    "        for entry in plan:\n",
    "            scenario_id = entry['scenario']\n",
    "            phase_name = entry.get('phase') or AGENT_REGISTRY[agent_key]['default_phase']\n",
    "            \n",
    "            print(f\"\\n--- Evaluando {agent_key.upper()} en {scenario_id} ({phase_name}) ---\")\n",
    "            \n",
    "            # 1. Preparar Configuraci√≥n Com√∫n\n",
    "            try:\n",
    "                phase = resolve_phase(scenario_id, phase_name)\n",
    "                state_file_path = ensure_state_file(phase['state_file'])\n",
    "                env_overrides = build_env_overrides(state_file_path, headless=headless)\n",
    "                base_config = _base_env_config(env_overrides)\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error preparando configuraci√≥n: {e}\")\n",
    "                continue\n",
    "            \n",
    "            # ---------------------------------------------------------\n",
    "            # 2. Evaluar Agente Local (con su propio wrapper/env)\n",
    "            # ---------------------------------------------------------\n",
    "            registry_entry = AGENT_REGISTRY[agent_key]\n",
    "            agent_config = registry_entry['config_cls'](\n",
    "                env_config=base_config,\n",
    "                total_timesteps=1000 \n",
    "            )\n",
    "            local_agent_wrapper = registry_entry['agent_cls'](agent_config)\n",
    "            \n",
    "            local_model_path = os.path.join(MODELS_DIR, agent_key, f\"{scenario_id}_{phase_name}.zip\")\n",
    "            \n",
    "            # FIX: Tambi√©n buscar versi√≥n _stable.zip\n",
    "            if not os.path.exists(local_model_path):\n",
    "                stable_path = os.path.join(MODELS_DIR, agent_key, f\"{scenario_id}_{phase_name}_stable.zip\")\n",
    "                if os.path.exists(stable_path):\n",
    "                    local_model_path = stable_path\n",
    "            \n",
    "            if os.path.exists(local_model_path):\n",
    "                print(f\"Cargando modelo local: {local_model_path}\")\n",
    "                try:\n",
    "                    env_local = local_agent_wrapper.make_env()\n",
    "                    local_agent_wrapper.model = PPO.load(local_model_path)\n",
    "                    \n",
    "                    print(f\"Ejecutando evaluaci√≥n...\")\n",
    "                    metrics_local = evaluate_agent_model(local_agent_wrapper.model, env_local)\n",
    "                    env_local.close()\n",
    "                    \n",
    "                    print(f\"‚úÖ Local: Reward={metrics_local['mean_reward']:.2f}, Steps={metrics_local['mean_steps']:.0f}\")\n",
    "                    \n",
    "                    results.append({\n",
    "                        'Agent': agent_key.upper(),\n",
    "                        'Scenario': scenario_id,\n",
    "                        'Phase': phase_name,\n",
    "                        'Model': 'Local (Specialized)',\n",
    "                        'Reward': metrics_local['mean_reward'],\n",
    "                        'Steps': metrics_local['mean_steps']\n",
    "                    })\n",
    "                    \n",
    "                    # Liberar memoria\n",
    "                    del local_agent_wrapper.model\n",
    "                    del env_local\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Error evaluando local: {e}\")\n",
    "                    import traceback\n",
    "                    traceback.print_exc()\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è No existe modelo local en {local_model_path}\")\n",
    "\n",
    "            # ---------------------------------------------------------\n",
    "            # 3. Evaluar Baseline solo si est√° disponible\n",
    "            # ---------------------------------------------------------\n",
    "            if baseline_model:\n",
    "                print(\"Evaluando Baseline...\")\n",
    "                try:\n",
    "                    env_baseline = RedGymEnv(base_config)\n",
    "                    metrics_baseline = evaluate_agent_model(baseline_model, env_baseline)\n",
    "                    env_baseline.close()\n",
    "                    \n",
    "                    print(f\"‚úÖ Baseline: Reward={metrics_baseline['mean_reward']:.2f}, Steps={metrics_baseline['mean_steps']:.0f}\")\n",
    "                    \n",
    "                    results.append({\n",
    "                        'Agent': agent_key.upper(),\n",
    "                        'Scenario': scenario_id,\n",
    "                        'Phase': phase_name,\n",
    "                        'Model': 'Baseline (PPO v2)',\n",
    "                        'Reward': metrics_baseline['mean_reward'],\n",
    "                        'Steps': metrics_baseline['mean_steps']\n",
    "                    })\n",
    "                    \n",
    "                    del env_baseline\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Error evaluando baseline: {e}\")\n",
    "\n",
    "    return pd.DataFrame(results) if results else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c7f218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modo sin baseline activado (ahorra ~10GB RAM)\n",
      "\n",
      "--- Evaluando COMBAT en pewter_brock (battle) ---\n",
      "Cargando modelo local: c:\\Users\\javi1\\Documents\\repos_git\\TEL351-PokemonRed\\models_local\\combat\\pewter_brock_battle.zip\n",
      "Error evaluando local: too many values to unpack (expected 2)\n",
      "\n",
      "No se generaron resultados. Verifica que existan modelos entrenados.\n"
     ]
    }
   ],
   "source": [
    "# ==================== CONFIGURACI√ìN DE COMPARACI√ìN ====================\n",
    "# Para sistemas con 16GB RAM (con Windows usando ~10GB):\n",
    "# skip_baseline=True: Solo eval√∫a tus modelos (ahorra ~10GB)\n",
    "# skip_baseline=False: Intenta cargar el baseline (requiere >20GB RAM total)\n",
    "# ========================================================================\n",
    "\n",
    "BASELINE_MODEL_PATH = os.path.join(project_path, 'v2', 'runs', 'poke_26214400.zip')\n",
    "\n",
    "comparison_plans = {\n",
    "    'combat': combat_plan_local,\n",
    "    # 'puzzle': puzzle_plan_local,   # Comenta para evaluar menos modelos\n",
    "    # 'hybrid': hybrid_plan_local,   # Comenta para evaluar menos modelos\n",
    "}\n",
    "\n",
    "# IMPORTANTE: skip_baseline=True para ahorrar RAM\n",
    "df_results = run_comparison_lightweight(\n",
    "    comparison_plans, \n",
    "    baseline_path=BASELINE_MODEL_PATH, \n",
    "    headless=True,\n",
    "    skip_baseline=True  # Cambia a False solo si tienes >24GB RAM\n",
    ")\n",
    "\n",
    "if df_results is not None and not df_results.empty:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"           RESULTADOS DE EVALUACI√ìN\")\n",
    "    print(\"=\"*60)\n",
    "    print(df_results.to_string(index=False))\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Guardar CSV\n",
    "    csv_path = \"evaluacion_modelos_locales.csv\"\n",
    "    df_results.to_csv(csv_path, index=False)\n",
    "    print(f\"\\nResultados guardados en: {csv_path}\")\n",
    "else:\n",
    "    print(\"\\nNo se generaron resultados. Verifica que existan modelos entrenados.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b43e56f",
   "metadata": {},
   "source": [
    "## 11. Entrenar Baseline Ligero (Opcional - Alternativa al modelo pesado)\n",
    "\n",
    "Si quieres comparar tus agentes especializados con un baseline PPO gen√©rico **sin usar el modelo gigante de 26M pasos**, puedes entrenar tu propio baseline ligero aqu√≠. Este ser√° un modelo est√°ndar de `v2/red_gym_env_v2.py` entrenado con los **mismos 40k pasos** que tus agentes especializados para una comparaci√≥n justa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cb3fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from v2.red_gym_env_v2 import RedGymEnv\n",
    "\n",
    "def train_lightweight_baseline(scenario_id='pewter_brock', phase_name='battle', timesteps=40_000):\n",
    "    \"\"\"\n",
    "    Entrena un baseline PPO simple (sin wrappers especializados) para comparaci√≥n justa.\n",
    "    Usa el mismo n√∫mero de pasos que tus agentes especializados.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"   ENTRENANDO BASELINE LIGERO (PPO Gen√©rico)\")\n",
    "    print(f\"   Escenario: {scenario_id} | Fase: {phase_name}\")\n",
    "    print(f\"   Pasos: {timesteps:,}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Preparar configuraci√≥n del entorno (igual que tus agentes)\n",
    "    phase = resolve_phase(scenario_id, phase_name)\n",
    "    state_file_path = ensure_state_file(phase['state_file'])\n",
    "    env_overrides = build_env_overrides(state_file_path, headless=True)\n",
    "    base_config = _base_env_config(env_overrides)\n",
    "    \n",
    "    # Crear entorno est√°ndar (sin wrappers especializados)\n",
    "    env = RedGymEnv(base_config)\n",
    "    \n",
    "    # Crear modelo PPO con configuraci√≥n similar a tus agentes\n",
    "    model = PPO(\n",
    "        \"CnnPolicy\",  # Pol√≠tica est√°ndar para im√°genes\n",
    "        env,\n",
    "        learning_rate=2.5e-4,\n",
    "        n_steps=1024,\n",
    "        batch_size=256,\n",
    "        gamma=0.999,\n",
    "        verbose=1,\n",
    "        device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    )\n",
    "    \n",
    "    # Entrenar\n",
    "    try:\n",
    "        import tqdm, rich\n",
    "        model.learn(total_timesteps=timesteps, progress_bar=True)\n",
    "    except ImportError:\n",
    "        model.learn(total_timesteps=timesteps)\n",
    "    \n",
    "    # Guardar\n",
    "    baseline_dir = os.path.join(MODELS_DIR, 'baseline_lightweight')\n",
    "    os.makedirs(baseline_dir, exist_ok=True)\n",
    "    baseline_path = os.path.join(baseline_dir, f\"{scenario_id}_{phase_name}.zip\")\n",
    "    model.save(baseline_path)\n",
    "    \n",
    "    print(f\"\\nBaseline ligero guardado en: {baseline_path}\")\n",
    "    env.close()\n",
    "    \n",
    "    return baseline_path\n",
    "\n",
    "# Entrenar baseline (descomenta para ejecutar)\n",
    "# baseline_ligero_path = train_lightweight_baseline(\n",
    "#     scenario_id='pewter_brock',\n",
    "#     phase_name='battle',\n",
    "#     timesteps=40_000  # Mismo n√∫mero de pasos que tus agentes\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2107a20",
   "metadata": {},
   "source": [
    "### Comparar con Baseline Ligero\n",
    "\n",
    "Una vez entrenado el baseline ligero, puedes compararlo con tus agentes especializados usando esta celda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b83ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta al baseline ligero que acabas de entrenar\n",
    "BASELINE_LIGERO_PATH = os.path.join(project_path, 'models_local', 'baseline_lightweight', 'pewter_brock_battle.zip')\n",
    "\n",
    "# Comparar (solo si el baseline ligero existe)\n",
    "if os.path.exists(BASELINE_LIGERO_PATH):\n",
    "    print(\"Comparando con Baseline Ligero (entrenado con los mismos 40k pasos)\")\n",
    "    \n",
    "    df_comparison = run_comparison_lightweight(\n",
    "        {'combat': combat_plan_local},\n",
    "        baseline_path=BASELINE_LIGERO_PATH,\n",
    "        headless=True,\n",
    "        skip_baseline=False  # Ahora S√ç cargamos el baseline (es ligero)\n",
    "    )\n",
    "    \n",
    "    if df_comparison is not None and not df_comparison.empty:\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"     COMPARACI√ìN: AGENTE ESPECIALIZADO vs BASELINE LIGERO\")\n",
    "        print(\"=\"*70)\n",
    "        print(df_comparison.to_string(index=False))\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        # Calcular mejora\n",
    "        if len(df_comparison) == 2:\n",
    "            reward_especializado = df_comparison[df_comparison['Model'].str.contains('Specialized')]['Reward'].values[0]\n",
    "            reward_baseline = df_comparison[df_comparison['Model'].str.contains('Baseline')]['Reward'].values[0]\n",
    "            mejora = ((reward_especializado - reward_baseline) / abs(reward_baseline)) * 100\n",
    "            print(f\"\\nMejora del agente especializado: {mejora:+.1f}%\")\n",
    "        \n",
    "        df_comparison.to_csv(\"comparacion_especializado_vs_baseline_ligero.csv\", index=False)\n",
    "else:\n",
    "    print(f\"Baseline ligero no encontrado en: {BASELINE_LIGERO_PATH}\")\n",
    "    print(\"Ejecuta primero la celda anterior para entrenar el baseline ligero.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b376e231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluando en: Pewter City Gym - Brock\n",
      "Modelo: pewter_brock_battle.zip\n",
      "Modo Headless: False\n",
      "Cargando pesos del modelo...\n",
      "Inyectando configuraci√≥n de equipo e inventario...\n",
      "üåÄ Programando Warp a Mapa 54 (4, 13)...\n",
      "Calentando motor para warp (3s)...\n",
      "Inyectando configuraci√≥n de equipo e inventario...\n",
      "üåÄ Programando Warp a Mapa 54 (4, 13)...\n",
      "Calentando motor para warp (3s)...\n",
      "üìä M√©tricas iniciadas para CombatApex_Local en Gimnasio 1\n",
      "\n",
      "Iniciando ejecuci√≥n del agente...\n",
      "üìä M√©tricas iniciadas para CombatApex_Local en Gimnasio 1\n",
      "\n",
      "Iniciando ejecuci√≥n del agente...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\javi1\\anaconda3\\envs\\pokeenv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:243: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.\n",
      "  warnings.warn(\"You tried to call render() but no `render_mode` was passed to the env constructor.\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 245\u001b[0m\n\u001b[0;32m    242\u001b[0m SCENARIO_PATH \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(project_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgym_scenarios\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgym1_pewter_brock\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    244\u001b[0m \u001b[38;5;66;03m# Ejecutar (Cambiado a headless=False para ver qu√© pasa)\u001b[39;00m\n\u001b[1;32m--> 245\u001b[0m stats \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_gym_scenario\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSCENARIO_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheadless\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[14], line 172\u001b[0m, in \u001b[0;36mevaluate_gym_scenario\u001b[1;34m(model_path, scenario_path, headless)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIniciando ejecuci√≥n del agente...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m truncated:\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;66;03m# Predecir\u001b[39;00m\n\u001b[1;32m--> 172\u001b[0m     action, _ \u001b[38;5;241m=\u001b[39m \u001b[43magent_wrapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;66;03m# Ejecutar\u001b[39;00m\n\u001b[0;32m    175\u001b[0m     step_result \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n",
      "File \u001b[1;32mc:\\Users\\javi1\\anaconda3\\envs\\pokeenv\\lib\\site-packages\\stable_baselines3\\common\\base_class.py:556\u001b[0m, in \u001b[0;36mBaseAlgorithm.predict\u001b[1;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict\u001b[39m(\n\u001b[0;32m    537\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    538\u001b[0m     observation: Union[np\u001b[38;5;241m.\u001b[39mndarray, Dict[\u001b[38;5;28mstr\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray]],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    541\u001b[0m     deterministic: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    542\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[np\u001b[38;5;241m.\u001b[39mndarray, Optional[Tuple[np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]]]:\n\u001b[0;32m    543\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    544\u001b[0m \u001b[38;5;124;03m    Get the policy action from an observation (and optional hidden state).\u001b[39;00m\n\u001b[0;32m    545\u001b[0m \u001b[38;5;124;03m    Includes sugar-coating to handle different observations (e.g. normalizing images).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[38;5;124;03m        (used in recurrent policies)\u001b[39;00m\n\u001b[0;32m    555\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 556\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisode_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\javi1\\anaconda3\\envs\\pokeenv\\lib\\site-packages\\stable_baselines3\\common\\policies.py:365\u001b[0m, in \u001b[0;36mBasePolicy.predict\u001b[1;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(observation, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(observation) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(observation[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    357\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    358\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have passed a tuple to the predict() function instead of a Numpy array or a Dict. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    359\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are probably mixing Gym API with SB3 VecEnv API: `obs, info = env.reset()` (Gym) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand documentation for more information: https://stable-baselines3.readthedocs.io/en/master/guide/vec_envs.html#vecenv-api-vs-gym-api\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m     )\n\u001b[1;32m--> 365\u001b[0m obs_tensor, vectorized_env \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobs_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m th\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m    368\u001b[0m     actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict(obs_tensor, deterministic\u001b[38;5;241m=\u001b[39mdeterministic)\n",
      "File \u001b[1;32mc:\\Users\\javi1\\anaconda3\\envs\\pokeenv\\lib\\site-packages\\stable_baselines3\\common\\policies.py:276\u001b[0m, in \u001b[0;36mBaseModel.obs_to_tensor\u001b[1;34m(self, observation)\u001b[0m\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;66;03m# Add batch dimension if needed\u001b[39;00m\n\u001b[0;32m    274\u001b[0m     observation \u001b[38;5;241m=\u001b[39m observation\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_space\u001b[38;5;241m.\u001b[39mshape))  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m--> 276\u001b[0m obs_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mobs_as_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obs_tensor, vectorized_env\n",
      "File \u001b[1;32mc:\\Users\\javi1\\anaconda3\\envs\\pokeenv\\lib\\site-packages\\stable_baselines3\\common\\utils.py:487\u001b[0m, in \u001b[0;36mobs_as_tensor\u001b[1;34m(obs, device)\u001b[0m\n\u001b[0;32m    485\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m th\u001b[38;5;241m.\u001b[39mas_tensor(obs, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m    486\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obs, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m--> 487\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {key: th\u001b[38;5;241m.\u001b[39mas_tensor(_obs, device\u001b[38;5;241m=\u001b[39mdevice) \u001b[38;5;28;01mfor\u001b[39;00m (key, _obs) \u001b[38;5;129;01min\u001b[39;00m obs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized type of observation \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(obs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\javi1\\anaconda3\\envs\\pokeenv\\lib\\site-packages\\stable_baselines3\\common\\utils.py:487\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    485\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m th\u001b[38;5;241m.\u001b[39mas_tensor(obs, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m    486\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obs, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m--> 487\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {key: \u001b[43mth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_obs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m (key, _obs) \u001b[38;5;129;01min\u001b[39;00m obs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized type of observation \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(obs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# =================================================================================\n",
    "# EVALUACI√ìN DE AGENTE EN ESCENARIO DE GIMNASIO (HEADLESS + M√âTRICAS)\n",
    "# VERSI√ìN CORREGIDA: Maneja correctamente VecEnv y errores de tipos\n",
    "# =================================================================================\n",
    "\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from stable_baselines3 import PPO\n",
    "from gym_scenarios.gym_metrics import GymMetricsTracker\n",
    "\n",
    "# Importar direcciones de memoria necesarias para la inyecci√≥n\n",
    "PARTY_SIZE_ADDRESS = 0xD163\n",
    "PARTY_ADDRESSES = [0xD164, 0xD165, 0xD166, 0xD167, 0xD168, 0xD169]\n",
    "LEVELS_ADDRESSES = [0xD18C, 0xD1B8, 0xD1E4, 0xD210, 0xD23C, 0xD268]\n",
    "HP_ADDRESSES = [0xD16C, 0xD198, 0xD1C4, 0xD1F0, 0xD21C, 0xD248]\n",
    "MAX_HP_ADDRESSES = [0xD18D, 0xD1B9, 0xD1E5, 0xD211, 0xD23D, 0xD269]\n",
    "MONEY_ADDRESS_1 = 0xD347\n",
    "MONEY_ADDRESS_2 = 0xD348\n",
    "MONEY_ADDRESS_3 = 0xD349\n",
    "BADGE_COUNT_ADDRESS = 0xD356\n",
    "BAG_ITEMS_START = 0xD31E\n",
    "BAG_ITEM_COUNT = 0xD31D\n",
    "\n",
    "def get_base_env(env):\n",
    "    \"\"\"Obtiene el entorno base (RedGymEnv) de un wrapper o VecEnv.\"\"\"\n",
    "    if hasattr(env, 'envs'): # DummyVecEnv/SubprocVecEnv\n",
    "        env = env.envs[0]\n",
    "    if hasattr(env, 'unwrapped'):\n",
    "        return env.unwrapped\n",
    "    return env\n",
    "\n",
    "def inject_gym_config(env, config):\n",
    "    \"\"\"Inyecta la configuraci√≥n del equipo e inventario en la memoria del emulador.\"\"\"\n",
    "    base_env = get_base_env(env)\n",
    "    pyboy = base_env.pyboy\n",
    "    \n",
    "    def write_mem(addr, val):\n",
    "        if hasattr(pyboy, \"set_memory_value\"):\n",
    "            pyboy.set_memory_value(addr, val & 0xFF)\n",
    "        else:\n",
    "            pyboy.memory[addr] = val & 0xFF\n",
    "\n",
    "    def write_word(addr, val):\n",
    "        write_mem(addr, (val >> 8) & 0xFF)\n",
    "        write_mem(addr + 1, val & 0xFF)\n",
    "\n",
    "    def write_bcd(val):\n",
    "        return ((val // 10) << 4) | (val % 10)\n",
    "\n",
    "    print(\"Inyectando configuraci√≥n de equipo e inventario...\")\n",
    "\n",
    "    # 1. Equipo\n",
    "    team = config.get('player_team', [])\n",
    "    write_mem(PARTY_SIZE_ADDRESS, len(team))\n",
    "    for i, poke in enumerate(team):\n",
    "        slot = poke.get('slot', 1) - 1\n",
    "        if 0 <= slot < 6:\n",
    "            write_mem(PARTY_ADDRESSES[slot], poke.get('species_id', 0))\n",
    "            write_mem(LEVELS_ADDRESSES[slot], poke.get('level', 5))\n",
    "            write_word(HP_ADDRESSES[slot], poke.get('current_hp', 20))\n",
    "            write_word(MAX_HP_ADDRESSES[slot], poke.get('max_hp', 20))\n",
    "\n",
    "    # 2. Items\n",
    "    items = config.get('bag_items', [])\n",
    "    item_count = min(len(items), 20)\n",
    "    write_mem(BAG_ITEM_COUNT, item_count)\n",
    "    for i, item in enumerate(items[:20]):\n",
    "        base = BAG_ITEMS_START + (i * 2)\n",
    "        write_mem(base, item.get('item_id', 0))\n",
    "        write_mem(base + 1, item.get('quantity', 1))\n",
    "    write_mem(BAG_ITEMS_START + (item_count * 2), 0xFF)\n",
    "\n",
    "    # 3. Dinero y Medallas\n",
    "    money = config.get('money', 0)\n",
    "    write_mem(MONEY_ADDRESS_1, write_bcd(money // 10000))\n",
    "    write_mem(MONEY_ADDRESS_2, write_bcd((money // 100) % 100))\n",
    "    write_mem(MONEY_ADDRESS_3, write_bcd(money % 100))\n",
    "    write_mem(BADGE_COUNT_ADDRESS, config.get('badge_bits', 0))\n",
    "\n",
    "    # 4. Warp\n",
    "    start_pos = config.get('start_position', {'x': 4, 'y': 13})\n",
    "    map_id = config.get('map_id', 0)\n",
    "    \n",
    "    print(f\"üåÄ Programando Warp a Mapa {map_id} ({start_pos['x']}, {start_pos['y']})...\")\n",
    "    write_mem(0xD365, map_id)\n",
    "    write_mem(0xD366, start_pos['x'])\n",
    "    write_mem(0xD367, start_pos['y'])\n",
    "    \n",
    "    if hasattr(pyboy, \"get_memory_value\"):\n",
    "        current_wd72d = pyboy.get_memory_value(0xD12B)\n",
    "    else:\n",
    "        current_wd72d = pyboy.memory[0xD12B]\n",
    "    write_mem(0xD12B, current_wd72d | 0x08)\n",
    "    write_mem(0xD35D, 0x00)\n",
    "\n",
    "    return map_id, start_pos\n",
    "\n",
    "def evaluate_gym_scenario(model_path, scenario_path, headless=True):\n",
    "    \"\"\"Ejecuta la evaluaci√≥n completa de un escenario de gimnasio.\"\"\"\n",
    "    \n",
    "    # Rutas\n",
    "    state_file = os.path.join(scenario_path, \"gym_scenario.state\")\n",
    "    config_file = os.path.join(scenario_path, \"team_config.json\")\n",
    "    \n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"‚ùå Modelo no encontrado: {model_path}\")\n",
    "        return None\n",
    "    if not os.path.exists(state_file):\n",
    "        print(f\"‚ùå Estado no encontrado: {state_file}\")\n",
    "        return None\n",
    "    if not os.path.exists(config_file):\n",
    "        print(f\"‚ùå Configuraci√≥n no encontrada: {config_file}\")\n",
    "        return None\n",
    "\n",
    "    # Cargar Configuraci√≥n\n",
    "    with open(config_file, 'r') as f:\n",
    "        team_config = json.load(f)\n",
    "        \n",
    "    print(f\"\\n‚úÖ Evaluando en: {team_config.get('gym_name', 'Unknown Gym')}\")\n",
    "    print(f\"   Modelo: {os.path.basename(model_path)}\")\n",
    "    print(f\"   Modo Headless: {headless}\")\n",
    "\n",
    "    # Configurar Entorno\n",
    "    try:\n",
    "        env_overrides = build_env_overrides(state_file, headless=headless)\n",
    "        env_overrides['max_steps'] = 2048 * 5 \n",
    "        base_config = _base_env_config(env_overrides)\n",
    "        \n",
    "        # Instanciar Agente\n",
    "        agent_config = CombatAgentConfig(env_config=base_config, total_timesteps=1000)\n",
    "        agent_wrapper = CombatApexAgent(agent_config)\n",
    "        \n",
    "        # Cargar Modelo\n",
    "        print(\"üì¶ Cargando pesos del modelo...\")\n",
    "        agent_wrapper.model = PPO.load(model_path)\n",
    "        \n",
    "        # Crear Entorno\n",
    "        env = agent_wrapper.make_env()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error inicializando entorno/modelo: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "    \n",
    "    # Reset\n",
    "    try:\n",
    "        reset_result = env.reset()\n",
    "        obs = reset_result[0] if isinstance(reset_result, tuple) else reset_result\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error en reset: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Inyectar Configuraci√≥n\n",
    "    try:\n",
    "        target_map, target_pos = inject_gym_config(env, team_config)\n",
    "        base_env = get_base_env(env)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error inyectando configuraci√≥n: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Calentamiento para Warp\n",
    "    print(\"‚è≥ Calentando motor para warp (3s)...\")\n",
    "    for _ in range(180):\n",
    "        base_env.pyboy.tick(1, False)\n",
    "        if not headless:\n",
    "            env.render()\n",
    "            \n",
    "    # Verificar Warp\n",
    "    current_map = base_env.read_m(0xD35E)\n",
    "    if current_map != target_map:\n",
    "        print(f\"‚ö†Ô∏è Warp fall√≥. Mapa: {current_map}, Esperado: {target_map}. Reintentando...\")\n",
    "        inject_gym_config(env, team_config)\n",
    "        for _ in range(60):\n",
    "            base_env.pyboy.tick(1, False)\n",
    "            if not headless: env.render()\n",
    "        \n",
    "    # Inicializar Tracker\n",
    "    tracker = GymMetricsTracker(\n",
    "        gym_number=team_config.get('gym_number', 1),\n",
    "        agent_name=\"CombatApex_Local\",\n",
    "        gym_name=team_config.get('gym_name', \"\")\n",
    "    )\n",
    "    tracker.start()\n",
    "    \n",
    "    done = False\n",
    "    truncated = False\n",
    "    step_count = 0\n",
    "    max_steps = env_overrides.get('max_steps', 10000)\n",
    "    \n",
    "    print(\"\\nüéÆ Iniciando ejecuci√≥n del agente...\")\n",
    "    \n",
    "    try:\n",
    "        while not done and not truncated and step_count < max_steps:\n",
    "            \n",
    "            # Asegurar que obs no sea tupla\n",
    "            if isinstance(obs, tuple):\n",
    "                obs = obs[0]\n",
    "                \n",
    "            # Predecir\n",
    "            action, _ = agent_wrapper.model.predict(obs, deterministic=True)\n",
    "            \n",
    "            # Ejecutar\n",
    "            step_result = env.step(action)\n",
    "            \n",
    "            # Unpacking flexible\n",
    "            if len(step_result) == 4:\n",
    "                obs, reward, done, info = step_result\n",
    "                truncated = False\n",
    "            else:\n",
    "                obs, reward, done, truncated, info = step_result\n",
    "            \n",
    "            # Manejar VecEnv arrays\n",
    "            if isinstance(done, (list, np.ndarray)): \n",
    "                done = done[0] if len(done) > 0 else False\n",
    "            if isinstance(truncated, (list, np.ndarray)): \n",
    "                truncated = truncated[0] if len(truncated) > 0 else False\n",
    "            if isinstance(reward, (list, np.ndarray)): \n",
    "                reward = reward[0] if len(reward) > 0 else 0\n",
    "            \n",
    "            # Renderizar\n",
    "            if not headless:\n",
    "                env.render()\n",
    "                \n",
    "            # Registrar m√©tricas\n",
    "            game_state = {\n",
    "                'x': int(base_env.read_m(0xD362)),\n",
    "                'y': int(base_env.read_m(0xD361)),\n",
    "                'map': int(base_env.read_m(0xD35E)),\n",
    "                'hp': [int(base_env.read_m(HP_ADDRESSES[i])) for i in range(6)],\n",
    "                'in_battle': bool(base_env.read_m(0xD057) != 0)\n",
    "            }\n",
    "            \n",
    "            action_scalar = int(action.item() if isinstance(action, np.ndarray) else action)\n",
    "            reward_scalar = float(reward)\n",
    "            \n",
    "            tracker.record_step(action_scalar, reward_scalar, game_state)\n",
    "            \n",
    "            # L√≥gica de batalla\n",
    "            if game_state['in_battle'] and not tracker.battle_started:\n",
    "                tracker.record_battle_start()\n",
    "            elif not game_state['in_battle'] and tracker.battle_started:\n",
    "                tracker.record_battle_end(won=True) \n",
    "            \n",
    "            step_count += 1\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n‚è∏Ô∏è Evaluaci√≥n interrumpida por usuario\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error durante evaluaci√≥n: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    finally:\n",
    "        env.close()\n",
    "    \n",
    "    # Finalizar\n",
    "    tracker.end(success=tracker.battle_won)\n",
    "    tracker.save_metrics(output_dir=\"metrics_evaluation\")\n",
    "    \n",
    "    stats = tracker.get_summary_stats()\n",
    "    print(\"\\nüìä Resumen de Evaluaci√≥n:\")\n",
    "    print(json.dumps(stats, indent=2))\n",
    "    \n",
    "    # Diagn√≥stico\n",
    "    if not stats['battle_won']:\n",
    "        print(\"\\n‚ö†Ô∏è DIAGN√ìSTICO DE FALLO:\")\n",
    "        if stats['unique_tiles_explored'] <= 1:\n",
    "            print(\"   üî¥ AGENTE INM√ìVIL: Solo explor√≥ 1 baldosa.\")\n",
    "        elif stats['battle_steps'] == 0:\n",
    "            print(\"   üü† NO ENTR√ì A BATALLA: El agente se movi√≥ pero no inici√≥ combate.\")\n",
    "            \n",
    "    return stats\n",
    "\n",
    "# --- EJECUTAR EVALUACI√ìN ---\n",
    "MODEL_PATH = os.path.join(project_path, 'models_local', 'combat', 'pewter_brock_battle_stable.zip')\n",
    "SCENARIO_PATH = os.path.join(project_path, 'gym_scenarios', 'gym1_pewter_brock')\n",
    "\n",
    "if os.path.exists(MODEL_PATH) and os.path.exists(SCENARIO_PATH):\n",
    "    stats = evaluate_gym_scenario(MODEL_PATH, SCENARIO_PATH, headless=False)\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Falta modelo o escenario:\")\n",
    "    print(f\"   Modelo: {MODEL_PATH} - {'‚úÖ' if os.path.exists(MODEL_PATH) else '‚ùå'}\")\n",
    "    print(f\"   Escenario: {SCENARIO_PATH} - {'‚úÖ' if os.path.exists(SCENARIO_PATH) else '‚ùå'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c658e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## üìö Resumen de Mejoras del Notebook\n",
    "\n",
    "Este notebook ha sido **potenciado** con las siguientes mejoras para evitar errores durante el entrenamiento:\n",
    "\n",
    "### ‚úÖ Nuevas Caracter√≠sticas\n",
    "\n",
    "1. **Diagn√≥stico Pre-Entrenamiento Autom√°tico**\n",
    "   - Verifica PyTorch, GPU, dependencias, archivos .state y espacio en disco\n",
    "   - Detecta problemas ANTES de empezar a entrenar\n",
    "\n",
    "2. **Reparaci√≥n Autom√°tica de PyTorch**\n",
    "   - Soluciona el error WinError 126 (DLLs corruptas)\n",
    "   - Reinstala PyTorch con soporte CUDA para RTX 3050\n",
    "\n",
    "3. **Entrenamiento Simplificado y Robusto**\n",
    "   - Busca autom√°ticamente el mejor archivo .state\n",
    "   - Valida cada paso antes de ejecutar\n",
    "   - Manejo completo de excepciones\n",
    "   - Configuraci√≥n estable que garantiza convergencia\n",
    "\n",
    "4. **Correcciones en Evaluaci√≥n**\n",
    "   - Manejo correcto de VecEnv vs Env est√°ndar\n",
    "   - Fix para deserializaci√≥n de observaciones\n",
    "   - Conversi√≥n robusta de tipos (numpy ‚Üí Python)\n",
    "\n",
    "5. **Mejor Feedback al Usuario**\n",
    "   - Mensajes claros con emojis y colores\n",
    "   - Diagn√≥stico autom√°tico de fallos\n",
    "   - Instrucciones paso a paso para solucionar problemas\n",
    "\n",
    "### üéØ C√≥mo Usar Este Notebook\n",
    "\n",
    "**Flujo recomendado:**\n",
    "\n",
    "1. **Ejecuta celdas 1-3**: Configuraci√≥n inicial y verificaci√≥n de entorno\n",
    "2. **Ejecuta celda de Diagn√≥stico**: Verifica que todo est√© listo\n",
    "3. **Si GPU falla**: Ejecuta celda de Reparaci√≥n de PyTorch ‚Üí Reinicia kernel\n",
    "4. **Ejecuta celda de Entrenamiento Simplificado**: ¬°Listo!\n",
    "\n",
    "**Para entrenamientos largos:**\n",
    "- Cambia `TIMESTEPS = 500_000` (o m√°s)\n",
    "- Usa `HEADLESS = True` para evitar ralentizaciones\n",
    "- Aumenta `NUM_ENVS = 8` si tienes CPU potente\n",
    "\n",
    "### ‚ö†Ô∏è Problemas Comunes Resueltos\n",
    "\n",
    "| Problema Original | Soluci√≥n Implementada |\n",
    "|-------------------|----------------------|\n",
    "| WinError 126 (PyTorch corrupto) | Celda de reparaci√≥n autom√°tica |\n",
    "| value_loss > 1000 | Configuraci√≥n estable con LR reducido |\n",
    "| VecEnv unpacking errors | Fix en evaluate_agent_model |\n",
    "| GPU no detectada | Diagn√≥stico + instrucciones de reinstalaci√≥n |\n",
    "| Archivos .state no encontrados | B√∫squeda autom√°tica con fallback |\n",
    "| Kernel crash (OpenMP) | Auto-configuraci√≥n de KMP_DUPLICATE_LIB_OK |\n",
    "\n",
    "### üìä M√©tricas de √âxito\n",
    "\n",
    "**Entrenamiento exitoso si ves:**\n",
    "- ‚úÖ `value_loss` < 100 (idealmente < 10)\n",
    "- ‚úÖ `explained_variance` > 0.3 (mejorando hacia 0.7+)\n",
    "- ‚úÖ `approx_kl` < 0.05\n",
    "- ‚úÖ Reward aumentando gradualmente\n",
    "\n",
    "**Se√±ales de problema:**\n",
    "- ‚ùå `value_loss` > 1000 y creciente\n",
    "- ‚ùå `explained_variance` < 0.1\n",
    "- ‚ùå Reward constante o decreciente\n",
    "- ‚ùå Kernel crash repetido\n",
    "\n",
    "Si ves se√±ales de problema, ejecuta primero la celda de Diagn√≥stico.\n",
    "\n",
    "---\n",
    "\n",
    "**√öltima actualizaci√≥n**: Noviembre 2025\n",
    "**Compatibilidad**: RTX 3050, Windows 11, 16GB RAM, Python 3.10+"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
