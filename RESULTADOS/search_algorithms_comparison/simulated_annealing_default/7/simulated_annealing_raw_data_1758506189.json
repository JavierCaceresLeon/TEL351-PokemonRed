{
  "algorithm_config": {
    "name": "Simulated Annealing",
    "algorithm": "simulated_annealing",
    "params": {}
  },
  "execution_summary": {
    "steps": 5,
    "time_seconds": 0.0,
    "total_reward": 11.65,
    "termination_reason": "Pokemon obtenido",
    "pokemon_obtained": true
  },
  "action_statistics": {
    "0": 0,
    "1": 1,
    "2": 1,
    "3": 1,
    "4": 0,
    "5": 1,
    "6": 1
  },
  "position_history": [
    [
      14,
      13
    ],
    [
      0,
      9
    ],
    [
      13,
      6
    ],
    [
      17,
      18
    ],
    [
      4,
      3
    ]
  ],
  "reward_history": [
    0.01,
    0.02,
    0.03,
    0.04,
    11.55
  ],
  "agent_info_samples": [
    {
      "algorithm": "Simulated Annealing",
      "current_position": [
        14,
        13
      ],
      "current_energy": 16.0,
      "best_energy": 16.0,
      "temperature": 100.0,
      "acceptance_rate": 0.0,
      "accepted_moves": 1,
      "rejected_moves": 0,
      "steps_without_improvement": 0,
      "visited_positions": 1,
      "step_count": 1,
      "recent_actions": [
        3
      ]
    },
    {
      "algorithm": "Simulated Annealing",
      "current_position": [
        0,
        9
      ],
      "current_energy": 8.0,
      "best_energy": 8.0,
      "temperature": 100.0,
      "acceptance_rate": 0.0,
      "accepted_moves": 2,
      "rejected_moves": 0,
      "steps_without_improvement": 0,
      "visited_positions": 2,
      "step_count": 2,
      "recent_actions": [
        3,
        5
      ]
    },
    {
      "algorithm": "Simulated Annealing",
      "current_position": [
        13,
        6
      ],
      "current_energy": 11.0,
      "best_energy": 8.0,
      "temperature": 100.0,
      "acceptance_rate": 0.0,
      "accepted_moves": 3,
      "rejected_moves": 0,
      "steps_without_improvement": 1,
      "visited_positions": 3,
      "step_count": 3,
      "recent_actions": [
        3,
        5,
        6
      ]
    },
    {
      "algorithm": "Simulated Annealing",
      "current_position": [
        17,
        18
      ],
      "current_energy": 24.0,
      "best_energy": 8.0,
      "temperature": 100.0,
      "acceptance_rate": 0.0,
      "accepted_moves": 4,
      "rejected_moves": 0,
      "steps_without_improvement": 2,
      "visited_positions": 4,
      "step_count": 4,
      "recent_actions": [
        3,
        5,
        6,
        2
      ]
    },
    {
      "algorithm": "Simulated Annealing",
      "current_position": [
        4,
        3
      ],
      "current_energy": 3.0,
      "best_energy": 3.0,
      "temperature": 100.0,
      "acceptance_rate": 0.0,
      "accepted_moves": 5,
      "rejected_moves": 0,
      "steps_without_improvement": 0,
      "visited_positions": 5,
      "step_count": 5,
      "recent_actions": [
        3,
        5,
        6,
        2,
        1
      ]
    }
  ],
  "performance_metrics": {
    "positions_visited": 5,
    "efficiency": 2.33,
    "speed": 50.0,
    "most_used_action": 1,
    "action_diversity": 5
  }
}