{
  "algorithm_config": {
    "name": "Simulated Annealing",
    "algorithm": "simulated_annealing",
    "params": {}
  },
  "execution_summary": {
    "steps": 8,
    "time_seconds": 0.0015146732330322266,
    "total_reward": 12.36,
    "termination_reason": "Pokemon obtenido",
    "pokemon_obtained": true
  },
  "action_statistics": {
    "0": 0,
    "1": 1,
    "2": 2,
    "3": 2,
    "4": 1,
    "5": 2,
    "6": 0
  },
  "position_history": [
    [
      18,
      17
    ],
    [
      17,
      8
    ],
    [
      14,
      0
    ],
    [
      15,
      1
    ],
    [
      13,
      12
    ],
    [
      3,
      13
    ],
    [
      1,
      1
    ],
    [
      1,
      5
    ]
  ],
  "reward_history": [
    0.01,
    0.02,
    0.03,
    0.04,
    0.05,
    0.06,
    0.5700000000000001,
    11.58
  ],
  "agent_info_samples": [
    {
      "algorithm": "Simulated Annealing",
      "current_position": [
        18,
        17
      ],
      "current_energy": 24.0,
      "best_energy": 24.0,
      "temperature": 100.0,
      "acceptance_rate": 0.0,
      "accepted_moves": 1,
      "rejected_moves": 0,
      "steps_without_improvement": 0,
      "visited_positions": 1,
      "step_count": 1,
      "recent_actions": [
        1
      ]
    },
    {
      "algorithm": "Simulated Annealing",
      "current_position": [
        17,
        8
      ],
      "current_energy": 14.0,
      "best_energy": 14.0,
      "temperature": 100.0,
      "acceptance_rate": 0.0,
      "accepted_moves": 2,
      "rejected_moves": 0,
      "steps_without_improvement": 0,
      "visited_positions": 2,
      "step_count": 2,
      "recent_actions": [
        1,
        2
      ]
    },
    {
      "algorithm": "Simulated Annealing",
      "current_position": [
        14,
        0
      ],
      "current_energy": 14.0,
      "best_energy": 14.0,
      "temperature": 100.0,
      "acceptance_rate": 0.0,
      "accepted_moves": 3,
      "rejected_moves": 0,
      "steps_without_improvement": 1,
      "visited_positions": 3,
      "step_count": 3,
      "recent_actions": [
        1,
        2,
        5
      ]
    },
    {
      "algorithm": "Simulated Annealing",
      "current_position": [
        15,
        1
      ],
      "current_energy": 14.0,
      "best_energy": 14.0,
      "temperature": 100.0,
      "acceptance_rate": 0.0,
      "accepted_moves": 4,
      "rejected_moves": 0,
      "steps_without_improvement": 2,
      "visited_positions": 4,
      "step_count": 4,
      "recent_actions": [
        1,
        2,
        5,
        4
      ]
    },
    {
      "algorithm": "Simulated Annealing",
      "current_position": [
        13,
        12
      ],
      "current_energy": 14.0,
      "best_energy": 14.0,
      "temperature": 100.0,
      "acceptance_rate": 0.0,
      "accepted_moves": 5,
      "rejected_moves": 0,
      "steps_without_improvement": 3,
      "visited_positions": 5,
      "step_count": 5,
      "recent_actions": [
        1,
        2,
        5,
        4,
        3
      ]
    },
    {
      "algorithm": "Simulated Annealing",
      "current_position": [
        3,
        13
      ],
      "current_energy": 9.0,
      "best_energy": 9.0,
      "temperature": 100.0,
      "acceptance_rate": 0.0,
      "accepted_moves": 6,
      "rejected_moves": 0,
      "steps_without_improvement": 0,
      "visited_positions": 6,
      "step_count": 6,
      "recent_actions": [
        2,
        5,
        4,
        3,
        5
      ]
    },
    {
      "algorithm": "Simulated Annealing",
      "current_position": [
        1,
        1
      ],
      "current_energy": 5.0,
      "best_energy": 5.0,
      "temperature": 100.0,
      "acceptance_rate": 0.0,
      "accepted_moves": 7,
      "rejected_moves": 0,
      "steps_without_improvement": 0,
      "visited_positions": 7,
      "step_count": 7,
      "recent_actions": [
        5,
        4,
        3,
        5,
        3
      ]
    },
    {
      "algorithm": "Simulated Annealing",
      "current_position": [
        1,
        5
      ],
      "current_energy": 3.0,
      "best_energy": 3.0,
      "temperature": 100.0,
      "acceptance_rate": 0.0,
      "accepted_moves": 8,
      "rejected_moves": 0,
      "steps_without_improvement": 0,
      "visited_positions": 8,
      "step_count": 8,
      "recent_actions": [
        4,
        3,
        5,
        3,
        2
      ]
    }
  ],
  "performance_metrics": {
    "positions_visited": 8,
    "efficiency": 1.545,
    "speed": 80.0,
    "most_used_action": 2,
    "action_diversity": 5
  }
}