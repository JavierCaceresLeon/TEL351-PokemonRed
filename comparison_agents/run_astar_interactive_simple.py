"""
Simple Interactive A* Agent for Pokemon Red
==========================================

Run the A* agent continuously like epsilon greedy - no episodes, just one session.
"""

import time
import numpy as np
import os
from pathlib import Path
from v2_astar_agent import V2AStarAgent

if __name__ == "__main__":
    print("ğŸŒŸ Interactive A* Search Agent for Pokemon Red")
    print("ğŸ§­ Intelligent pathfinding with goal-directed exploration")
    print("â¹ï¸  Press Ctrl+C to stop at any time")
    print()
    
    # Session and environment configuration
    sess_path = Path(f'astar_session_{str(time.time_ns())[:8]}')
    ep_length = 2**23
    
    # Environment configuration for interactive v2 mode
    env_config = {
        'headless': False,
        'save_final_state': True,
        'early_stop': False,
        'action_freq': 24,
        'init_state': '../has_pokedex.state',
        'max_steps': ep_length,
        'print_rewards': True,
        'save_video': False,
        'fast_video': True,
        'session_path': sess_path,
        'gb_path': '../PokemonRed.gb',
        'debug': False,
        'sim_frame_dist': 2_000_000.0
    }
    
    # A* specific configuration
    agent_config = {
        'exploration_bonus': 0.2,
        'stuck_threshold': 50,
    }
    
    print("âš™ï¸  A* Agent Configuration:")
    print(f"   ğŸ¯ Exploration Bonus: {agent_config['exploration_bonus']}")
    print(f"   ğŸš« Stuck Threshold: {agent_config['stuck_threshold']}")
    print()
    
    try:
        # Initialize A* agent
        print("ğŸ¤– Initializing A* Search Agent...")
        agent = V2AStarAgent(env_config, agent_config, enable_logging=True)
        print("âœ… A* Agent ready!")
        print()
        
        print("ğŸ”„ Resetting environment...")
        observation, info = agent.env.reset()
        print("âœ… Environment reset complete")
        print()
        
        print("ğŸ® Interactive Mode Active:")
        print("   ğŸ“º Game Boy window is open")
        print("   ğŸ§­ A* pathfinding in progress")
        print("   ğŸ¯ Goal-directed exploration enabled")
        print()
        
        # Continuous execution like epsilon greedy
        step = 0
        total_reward = 0
        start_time = time.time()
        
        print("ğŸš€ Starting A* continuous session...")
        print("â¹ï¸  Press Ctrl+C in terminal to stop")
        print("=" * 50)
        
        while True:
            try:
                # Extract game state and enhanced observation like the wrapper does
                game_state = agent.extract_game_state(observation)
                enhanced_obs = agent.enhance_observation_with_heuristics(observation)
                
                # Get action from A* agent directly
                action, decision_info = agent.agent.select_action(enhanced_obs, game_state)
                
                # Execute action
                observation, reward, terminated, truncated, info = agent.env.step(action)
                agent.env.render()
                
                step += 1
                total_reward += reward
                
                # Print progress every 1000 steps
                if step % 1000 == 0:
                    elapsed = time.time() - start_time
                    steps_per_sec = step / elapsed if elapsed > 0 else 0
                    unique_positions = len(getattr(agent.agent, 'visited_positions', set()))
                    current_objective = getattr(agent.agent, 'current_objective', 'exploring')
                    print(f"ğŸ“Š Step {step:,} | Reward: {total_reward:.2f} | "
                          f"Positions: {unique_positions} | Objective: {current_objective} | "
                          f"Speed: {steps_per_sec:.1f} steps/sec")
                
                if terminated or truncated:
                    print("ğŸ Episode terminated, resetting...")
                    observation, info = agent.env.reset()
                    total_reward = 0
                
            except KeyboardInterrupt:
                print("\nğŸ›‘ Stopping A* session...")
                break
            except Exception as e:
                print(f"\nâŒ Error during execution: {e}")
                break
        
        # Final statistics
        elapsed = time.time() - start_time
        print("\n" + "=" * 50)
        print("ğŸ¯ A* Session Results:")
        print(f"ğŸš¶ Total Steps: {step:,}")
        print(f"ğŸ† Total Reward: {total_reward:.2f}")
        print(f"â±ï¸  Session Duration: {elapsed:.1f} seconds")
        if elapsed > 0:
            print(f"âš¡ Average Speed: {step/elapsed:.1f} steps/second")
        print("ğŸŒŸ A* session completed!")
        
    except Exception as e:
        print(f"âŒ Error initializing A* agent: {e}")
        import traceback
        traceback.print_exc()
        
    finally:
        try:
            if 'agent' in locals():
                agent.env.close()
                print("ğŸ”’ Environment closed")
        except:
            pass