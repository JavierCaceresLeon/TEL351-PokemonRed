# Gu√≠a de Desarrollo del Combat Agent - Pokemon Red

## üìã Resumen

Este documento describe los componentes exitosos del proyecto Combat Agent para Pokemon Red, desarrollado con PPO (Proximal Policy Optimization) y PyBoy. El objetivo es entrenar un agente especializado en combates Pokemon que supere al baseline general.

---

## üéØ Componentes Principales

### 1. Generaci√≥n de Estados de Batalla V√°lidos

#### `generate_clean_battle_states.py`
**Prop√≥sito:** Generar archivos `.state` con batallas activas para entrenamiento especializado.

**Problema resuelto:** Los estados guardados manualmente o pre-existentes no capturaban el momento exacto del inicio de batalla, causando que los agentes entrenados exploraran en vez de combatir.

**Funcionamiento:**
1. Carga el modelo baseline pre-entrenado
2. Navega autom√°ticamente hasta un gimnasio espec√≠fico
3. Detecta cuando inicia una batalla (monitor de `battle_type` en memoria `0xD057`)
4. Espera 5 frames para estabilizar el estado de batalla
5. Guarda el `.state` con la batalla activa

**Uso:**
```powershell
python generate_clean_battle_states.py --target-gym pewter --headless
```

**Gimnasios soportados:**
- `pewter` (Brock) - Map ID: 52
- `cerulean` (Misty) - Map ID: 65
- `vermilion` (Lt. Surge) - Map ID: 92

**Salida:**
- Directorio: `generated_battle_states/`
- Archivo: `clean_pewter_gym.state` (o similar seg√∫n gimnasio)

---

#### `verify_battle_state.py`
**Prop√≥sito:** Verificar que un archivo `.state` contiene una batalla activa.

**Informaci√≥n que muestra:**
- ‚úÖ Battle Type (0=none, 1=wild, 2=trainer)
- üìç Map ID y posici√≥n (x, y)
- üíö HP del jugador
- üíî HP del enemigo
- üèõÔ∏è Identificaci√≥n de gimnasio

**Uso:**
```powershell
python verify_battle_state.py generated_battle_states\clean_pewter_gym.state
```

**Ejemplo de salida v√°lida:**
```
‚öîÔ∏è  Estado de Batalla:
   Battle Type: 1 (Wild Pokemon)

üìä Diagn√≥stico:
   ‚úÖ Estado V√ÅLIDO - Batalla en progreso
```

---

### 2. Entrenamiento Especializado en Combate

#### `train_battle_loop.py`
**Prop√≥sito:** Entrenar un agente PPO especializado en combate mediante loop de batallas repetidas.

**Sistema de recompensas optimizado:**
- ‚úÖ Da√±o causado: **+3.0 por HP**
- ‚ùå Da√±o recibido: **-2.0 por HP**
- üèÜ Victoria: **+1000**
- üíé Victoria perfecta (sin da√±o): **+1300**
- üèÉ Huir con >50% HP: **-500** (penalizaci√≥n fuerte)
- ‚ò†Ô∏è Derrota: **-300**

**Caracter√≠sticas clave:**
- Loop infinito de la misma batalla (m√°ximo aprendizaje por repetici√≥n)
- Reinicio autom√°tico tras cada batalla (victoria/derrota/huida)
- Checkpoints cada 50,000 timesteps
- Compatible con modelos pre-entrenados

**Uso:**
```powershell
python train_battle_loop.py \
  --model sessions\combat_agent_final\combat_agent_final.zip \
  --battle-state generated_battle_states\clean_pewter_gym.state \
  --timesteps 500000 \
  --learning-rate 0.0003
```

**Par√°metros:**
- `--model`: Modelo base a continuar entrenando
- `--battle-state`: Estado de batalla v√°lido (.state)
- `--timesteps`: Cantidad de pasos de entrenamiento
- `--learning-rate`: Tasa de aprendizaje (default: 0.0003)

**Salida:**
- Directorio: `sessions/{modelo}_battle_loop/`
- Modelo final: `{modelo}_battle_loop.zip`
- Checkpoints: `sessions/{modelo}_battle_loop/checkpoints/`

---

#### `red_gym_env_v2.py`
**Prop√≥sito:** Ambiente base de Gymnasium para Pokemon Red con PyBoy 2.6+.

**Configuraci√≥n cr√≠tica para evitar crashes:**
```python
pyboy = PyBoy(
    rom_path,
    window='headless',  # NO usar 'null' (crashes)
    sound=False,
    cgb=False,          # Deshabilitar Game Boy Color
    sound_emulated=False
)
```

**Caracter√≠sticas:**
- Compatible con observaciones Dict (MultiInputPolicy)
- Carga autom√°tica de estados iniciales en `reset()`
- Lectura de memoria del juego para m√©tricas
- Sin logging excesivo (optimizado para entrenamiento largo)

---

### 3. Estructura de Directorios

```
PokemonCombatAgent/
‚îú‚îÄ‚îÄ generated_battle_states/          # Estados de batalla v√°lidos
‚îÇ   ‚îú‚îÄ‚îÄ clean_pewter_gym.state        # ‚úÖ Batalla activa (Pewter Gym)
‚îÇ   ‚îî‚îÄ‚îÄ manual_save_pewter.state      # Respaldo manual
‚îÇ
‚îú‚îÄ‚îÄ sessions/                         # Modelos entrenados
‚îÇ   ‚îú‚îÄ‚îÄ combat_agent_final/           # Entrenamiento base (1.5M steps)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ combat_agent_final.zip    # Modelo principal
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ checkpoints/              # Checkpoints cada 50K
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ PPO_1/ ... PPO_6/         # Logs TensorBoard
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ combat_agent_final_battle_loop/  # Entrenamiento especializado
‚îÇ       ‚îú‚îÄ‚îÄ combat_agent_final_battle_loop.zip
‚îÇ       ‚îú‚îÄ‚îÄ checkpoints/
‚îÇ       ‚îî‚îÄ‚îÄ PPO_1/                    # Logs TensorBoard
‚îÇ
‚îî‚îÄ‚îÄ comparison_results/               # Resultados de comparaciones
    ‚îî‚îÄ‚îÄ analysis_YYYYMMDD_HHMMSS/
        ‚îú‚îÄ‚îÄ COMPARISON_REPORT.md
        ‚îî‚îÄ‚îÄ *.png (gr√°ficos)
```

---

### 4. Comparaci√≥n y An√°lisis

#### `compare_models_interactive.py`
**Prop√≥sito:** Comparar rendimiento de dos modelos en el mismo escenario de batalla.

**Caracter√≠sticas:**
- Ejecuci√≥n secuencial (evita conflictos SDL2)
- M√©tricas de combate: HP dealt/taken, victorias, recompensas
- Resultados guardados en JSON para an√°lisis posterior

**Uso:**
```powershell
python compare_models_interactive.py \
  --combat-model sessions\combat_agent_final_battle_loop\combat_agent_final_battle_loop.zip \
  --baseline-model ..\PokemonRedExperiments\v2\runs\poke_26214400.zip \
  --battle-state generated_battle_states\clean_pewter_gym.state \
  --episodes 10 \
  --max-steps 2000
```

**Salida:**
- Directorio: `comparison_results/`
- JSON: `comparison_YYYYMMDD_HHMMSS.json`

---

#### `analyze_comparison.py`
**Prop√≥sito:** Generar visualizaciones y reporte de comparaci√≥n entre modelos.

**Gr√°ficos generados:**
1. M√©tricas de combate (HP dealt/taken, victorias)
2. Comparaci√≥n por episodio
3. F√≥rmulas de recompensa
4. Engagement en batalla

**Uso:**
```powershell
python analyze_comparison.py
# Autom√°ticamente busca el JSON m√°s reciente
```

**Salida:**
- Directorio: `comparison_results/analysis_YYYYMMDD_HHMMSS/`
- 4 gr√°ficos PNG
- `COMPARISON_REPORT.md` con conclusiones

---

#### `analyze_training_metrics.py`
**Prop√≥sito:** Extraer y visualizar m√©tricas de entrenamiento desde logs TensorBoard.

**M√©tricas principales:**
- `rollout/ep_rew_mean`: Recompensa promedio por episodio
- `rollout/ep_len_mean`: Longitud promedio de episodio
- `train/explained_variance`: Qu√© tan bien predice el modelo
- `train/approx_kl`: Divergencia KL (estabilidad)
- `train/value_loss`: P√©rdida de la funci√≥n de valor
- `train/policy_gradient_loss`: P√©rdida del gradiente de pol√≠tica

**Uso:**
```powershell
python analyze_training_metrics.py \
  --session-dir sessions\combat_agent_final_battle_loop \
  --output-dir training_analysis
```

**Salida:**
- Directorio: `training_analysis/`
- Gr√°ficos PNG individuales por m√©trica
- `training_summary.png` (resumen de 4 m√©tricas clave)
- `metrics.csv` (datos exportables)
- `summary.json` (resumen estad√≠stico)

**Alternativa - TensorBoard en tiempo real:**
```powershell
tensorboard --logdir=sessions\combat_agent_final_battle_loop
# Abrir http://localhost:6006
```

---

## üîÑ Flujo de Trabajo Completo

### Paso 1: Generar Estado de Batalla V√°lido
```powershell
# Generar estado de batalla
python generate_clean_battle_states.py --target-gym pewter --headless

# Verificar que sea v√°lido
python verify_battle_state.py generated_battle_states\clean_pewter_gym.state
```

**Resultado esperado:** `‚úÖ Estado V√ÅLIDO - Batalla en progreso`

---

### Paso 2: Entrenar Agente Especializado
```powershell
# Entrenar desde modelo base
python train_battle_loop.py \
  --model sessions\combat_agent_final\combat_agent_final.zip \
  --battle-state generated_battle_states\clean_pewter_gym.state \
  --timesteps 500000
```

**Duraci√≥n estimada:** ~1-2 horas con GPU (RTX 3050)  
**Velocidad:** ~100-104 it/s

---

### Paso 3: Comparar con Baseline
```powershell
# Comparar modelos
python compare_models_interactive.py \
  --combat-model sessions\combat_agent_final_battle_loop\combat_agent_final_battle_loop.zip \
  --baseline-model ..\PokemonRedExperiments\v2\runs\poke_26214400.zip \
  --battle-state generated_battle_states\clean_pewter_gym.state \
  --episodes 10 \
  --max-steps 2000

# Generar an√°lisis
python analyze_comparison.py
```

**Salida:** Reporte markdown con gr√°ficos comparativos

---

### Paso 4: Analizar M√©tricas de Entrenamiento
```powershell
# Extraer m√©tricas
python analyze_training_metrics.py \
  --session-dir sessions\combat_agent_final_battle_loop

# O ver en tiempo real
tensorboard --logdir=sessions\combat_agent_final_battle_loop
```

---

## üìä M√©tricas Clave para Evaluar √âxito

### Durante el Entrenamiento
- **`explained_variance`**: Debe estar > 0.9 (modelo predice bien)
- **`approx_kl`**: Debe estar < 0.05 (entrenamiento estable)
- **`ep_rew_mean`**: Debe aumentar progresivamente
- **`fps`**: ~100 it/s con GPU (buena velocidad)

### En Comparaci√≥n
- **Win Rate**: % de batallas ganadas
- **Avg HP Dealt**: Da√±o promedio causado por episodio
- **Avg HP Taken**: Da√±o promedio recibido por episodio
- **Avg Reward**: Recompensa total promedio

**Objetivo:** Combat Agent > Baseline en todas las m√©tricas

---

## üõ†Ô∏è Configuraci√≥n GPU (NVIDIA)

```powershell
# Verificar PyTorch con CUDA
python -c "import torch; print(f'CUDA: {torch.cuda.is_available()}')"
# Debe imprimir: CUDA: True

# Verificar dispositivo durante entrenamiento
# Los logs mostrar√°n: "Using cuda device"
```

**Hardware probado:**
- GPU: NVIDIA RTX 3050
- CUDA: 11.8
- PyTorch: 2.7.1+cu118

---

## üìù Archivos de Configuraci√≥n Importantes

### `requirements.txt`
Dependencias principales:
- `stable-baselines3[extra]`: Algoritmo PPO
- `pyboy`: Emulador Game Boy
- `gymnasium`: API de ambientes RL
- `torch`: Backend para redes neuronales
- `tensorboard`: Logging de m√©tricas

### `PokemonRed.gb`
ROM de Pokemon Red (necesario en ra√≠z del proyecto)

---

## üö® Problemas Comunes Resueltos

### 1. "Estado INV√ÅLIDO - NO hay batalla activa"
**Causa:** Estado guardado antes/despu√©s de la batalla  
**Soluci√≥n:** Usar `generate_clean_battle_states.py` que detecta autom√°ticamente el inicio exacto

### 2. "Sound buffer overrun! 1602 of 1602"
**Causa:** PyBoy con audio habilitado  
**Soluci√≥n:** Configurar `window='headless'`, `sound=False`, `cgb=False`

### 3. Combat Agent no entra en batallas durante comparaci√≥n
**Causa:** Usar estado de exploraci√≥n (ej: `has_pokedex_nballs.state`)  
**Soluci√≥n:** Usar estado de batalla v√°lido de `generated_battle_states/`

### 4. Batalla se reinicia muy seguido
**Causa:** Agente termina batalla r√°pido (victoria/derrota/huida)  
**Explicaci√≥n:** Esto es NORMAL y esperado. PPO aprende jugando muchas batallas cortas, no una batalla infinita.

---

## üéØ Resultados Esperados

### Entrenamiento Exitoso
```
rollout/ep_rew_mean: +500 a +1000 (victorias frecuentes)
train/explained_variance: 0.90 - 0.99
train/approx_kl: 0.02 - 0.04
fps: 90-110 it/s (con GPU)
```

### Comparaci√≥n Exitosa
```
Combat Agent Win Rate: 60-80%
Baseline Win Rate: 30-50%
Combat Agent Avg HP Dealt: Mayor que Baseline
Combat Agent Avg HP Taken: Menor que Baseline
```

---

## üìö Referencias de Memoria del Juego

**Direcciones cr√≠ticas (red_gym_env_v2.py):**
```python
0xD057  # Battle type (0=none, 1=wild, 2=trainer)
0xD16C  # Player HP (2 bytes, big endian)
0xCFE6  # Enemy HP (2 bytes, big endian)
0xD35E  # Current map ID
0xD362  # X position
0xD361  # Y position
0xD356  # Badges count
```

**Map IDs de gimnasios:**
```python
52  # Pewter Gym (Brock)
65  # Cerulean Gym (Misty)
92  # Vermilion Gym (Lt. Surge)
176 # Celadon Gym (Erika)
177 # Fuchsia Gym (Koga)
178 # Saffron Gym (Sabrina)
180 # Cinnabar Gym (Blaine)
181 # Viridian Gym (Giovanni)
```

---

## üî¨ Pr√≥ximos Pasos Sugeridos

1. **Entrenar en m√∫ltiples gimnasios:**
   ```powershell
   python generate_clean_battle_states.py --target-gym cerulean
   python generate_clean_battle_states.py --target-gym vermilion
   ```

2. **Aumentar timesteps:**
   ```powershell
   python train_battle_loop.py --timesteps 1000000  # 1M steps
   ```

3. **Ajustar recompensas:**
   - Editar `BattleLoopEnv` en `train_battle_loop.py`
   - Experimentar con valores de da√±o/victoria

4. **Comparaci√≥n multi-gimnasio:**
   - Generar estados de varios gimnasios
   - Comparar rendimiento en diferentes escenarios

---

## ‚úÖ Checklist de Replicaci√≥n

- [ ] Instalar dependencias: `pip install -r requirements.txt`
- [ ] Verificar GPU: `python -c "import torch; print(torch.cuda.is_available())"`
- [ ] Copiar `PokemonRed.gb` al directorio ra√≠z
- [ ] Generar estado de batalla: `python generate_clean_battle_states.py --target-gym pewter --headless`
- [ ] Verificar estado: `python verify_battle_state.py generated_battle_states\clean_pewter_gym.state`
- [ ] Entrenar agente: `python train_battle_loop.py --model <modelo_base> --timesteps 500000`
- [ ] Comparar con baseline: `python compare_models_interactive.py ...`
- [ ] Analizar resultados: `python analyze_comparison.py`
- [ ] Revisar m√©tricas: `python analyze_training_metrics.py --session-dir sessions\<nombre_sesion>`

---

## üìÑ Archivos del Proyecto (Solo Exitosos)

### Scripts Principales
- ‚úÖ `generate_clean_battle_states.py` - Generador de estados v√°lidos
- ‚úÖ `verify_battle_state.py` - Verificador de estados
- ‚úÖ `train_battle_loop.py` - Entrenamiento especializado
- ‚úÖ `compare_models_interactive.py` - Comparaci√≥n de modelos
- ‚úÖ `analyze_comparison.py` - An√°lisis con visualizaciones
- ‚úÖ `analyze_training_metrics.py` - Extracci√≥n de m√©tricas

### Archivos de Ambiente
- ‚úÖ `red_gym_env_v2.py` - Ambiente base Gymnasium
- ‚úÖ `requirements.txt` - Dependencias

### Archivos de Datos
- ‚úÖ `generated_battle_states/clean_pewter_gym.state` - Estado de batalla v√°lido
- ‚úÖ `sessions/combat_agent_final/combat_agent_final.zip` - Modelo base entrenado
- ‚úÖ `PokemonRed.gb` - ROM del juego

### Archivos Descartados (No usar)
- ‚ùå `battle_states/*.state` - Estados corruptos/bugueados
- ‚ùå `has_pokedex_nballs.state` - Estado de exploraci√≥n (no combate)
- ‚ùå `train_battle_specialist_emergency.py` - Enfoque anterior no exitoso
- ‚ùå `combat_focused_env.py` - Reemplazado por train_battle_loop.py

---

**√öltima actualizaci√≥n:** 30 de Noviembre, 2025  
**Versi√≥n:** 1.0  
**Estado:** Funcional y probado con √©xito
